{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outperf vs index 1m</th>\n",
       "      <th>outperf vs index 3m</th>\n",
       "      <th>ST momentum</th>\n",
       "      <th>LT momentum</th>\n",
       "      <th>Index vs max</th>\n",
       "      <th>Index st momentum</th>\n",
       "      <th>ebit vs peak</th>\n",
       "      <th>net income vs peak</th>\n",
       "      <th>market cap vs peak</th>\n",
       "      <th>Margin vs peak</th>\n",
       "      <th>PE</th>\n",
       "      <th>xEbit</th>\n",
       "      <th>xSales</th>\n",
       "      <th>PE vs peak</th>\n",
       "      <th>xEbit vs peak</th>\n",
       "      <th>xSales vs peak</th>\n",
       "      <th>ND/market cap</th>\n",
       "      <th>outperf next  3 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007191</td>\n",
       "      <td>-0.083593</td>\n",
       "      <td>0.076685</td>\n",
       "      <td>-0.472196</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.042669</td>\n",
       "      <td>-0.016447</td>\n",
       "      <td>11.096157</td>\n",
       "      <td>8.764507</td>\n",
       "      <td>0.390003</td>\n",
       "      <td>-0.195909</td>\n",
       "      <td>-0.040863</td>\n",
       "      <td>-0.047339</td>\n",
       "      <td>0.046168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017525</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>-0.346791</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>-0.266321</td>\n",
       "      <td>-0.496339</td>\n",
       "      <td>-0.051437</td>\n",
       "      <td>-0.247309</td>\n",
       "      <td>17.685318</td>\n",
       "      <td>8.772884</td>\n",
       "      <td>0.592203</td>\n",
       "      <td>-0.051437</td>\n",
       "      <td>-0.043755</td>\n",
       "      <td>-0.218866</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002132</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.272849</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.035756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.453475</td>\n",
       "      <td>17.377210</td>\n",
       "      <td>0.837097</td>\n",
       "      <td>-0.235442</td>\n",
       "      <td>-0.168420</td>\n",
       "      <td>-0.027351</td>\n",
       "      <td>0.318709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.041664</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.556955</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.045119</td>\n",
       "      <td>12.874137</td>\n",
       "      <td>10.429705</td>\n",
       "      <td>0.975562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008045</td>\n",
       "      <td>-0.052801</td>\n",
       "      <td>0.498034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.251466</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.221638</td>\n",
       "      <td>4.630687</td>\n",
       "      <td>0.691503</td>\n",
       "      <td>-0.066863</td>\n",
       "      <td>-0.132443</td>\n",
       "      <td>-0.060985</td>\n",
       "      <td>0.141099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outperf vs index 1m  outperf vs index 3m  ST momentum  LT momentum  \\\n",
       "0             0.007191            -0.083593     0.076685    -0.472196   \n",
       "1            -0.017525             0.071289     0.009150    -0.346791   \n",
       "2            -0.002132             0.001588     0.024445     0.272849   \n",
       "3             0.044802             0.041664     0.204800     0.556955   \n",
       "4             0.001149             0.041071     0.026255     0.251466   \n",
       "\n",
       "   Index vs max  Index st momentum  ebit vs peak  net income vs peak  \\\n",
       "0          -0.2           0.017742      0.000000            0.000000   \n",
       "1          -0.2           0.017742     -0.266321           -0.496339   \n",
       "2          -0.2           0.017742      0.000000            0.000000   \n",
       "3          -0.2           0.017742      0.000000            0.000000   \n",
       "4          -0.2           0.017742      0.000000            0.000000   \n",
       "\n",
       "   market cap vs peak  Margin vs peak         PE      xEbit    xSales  \\\n",
       "0           -0.042669       -0.016447  11.096157   8.764507  0.390003   \n",
       "1           -0.051437       -0.247309  17.685318   8.772884  0.592203   \n",
       "2           -0.035756        0.000000  19.453475  17.377210  0.837097   \n",
       "3            0.000000       -0.045119  12.874137  10.429705  0.975562   \n",
       "4           -0.032763        0.000000   8.221638   4.630687  0.691503   \n",
       "\n",
       "   PE vs peak  xEbit vs peak  xSales vs peak  ND/market cap  \\\n",
       "0   -0.195909      -0.040863       -0.047339       0.046168   \n",
       "1   -0.051437      -0.043755       -0.218866       0.185074   \n",
       "2   -0.235442      -0.168420       -0.027351       0.318709   \n",
       "3    0.000000      -0.008045       -0.052801       0.498034   \n",
       "4   -0.066863      -0.132443       -0.060985       0.141099   \n",
       "\n",
       "   outperf next  3 months  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('databases/3m_training.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process database\n",
    "import numpy as np\n",
    "\n",
    "#save labels\n",
    "labels = np.array(features['outperf next  3 months'])\n",
    "#remove labels\n",
    "features=features.drop('outperf next  3 months', axis = 1)\n",
    "#save features names\n",
    "feature_list = list(features.columns)\n",
    "#convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split database in training and cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#stratify = labels allows for consistant class distribution between sets\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(features, labels, stratify = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Show distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ones in train set is 0.40494044993383327\n",
      "Percentage of ones in cv set is 0.40476190476190477\n"
     ]
    }
   ],
   "source": [
    "train_zeros = (y_train == 0).sum()\n",
    "train_ones = (y_train == 1).sum()\n",
    "train_pct = train_ones / (train_zeros + train_ones)\n",
    "print('Percentage of ones in train set is', train_pct )\n",
    "\n",
    "cv_zeros = (y_cv == 0).sum()\n",
    "cv_ones = (y_cv == 1).sum()\n",
    "cv_pct = cv_ones / (cv_zeros + cv_ones)\n",
    "print('Percentage of ones in cv set is', cv_pct )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 20, 40], \n",
    "    'n_estimators' : [50, 100, 200, 400],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 17]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def grid_search_wrapper(refit_score='accuracy_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_cv)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the cv data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the cv data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_cv, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for accuracy_score\n",
      "{'max_depth': 25, 'max_features': 17, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for accuracy_score on the cv data:\n",
      "     pred_neg  pred_pos\n",
      "neg       375        75\n",
      "pos       134       172\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search_wrapper(refit_score='accuracy_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.687</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.724</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.716</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.685</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.719</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.682</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.718</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.711</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_precision_score  mean_test_recall_score  \\\n",
       "302                      0.687                   0.595   \n",
       "282                      0.680                   0.578   \n",
       "283                      0.685                   0.577   \n",
       "307                      0.682                   0.576   \n",
       "305                      0.669                   0.573   \n",
       "\n",
       "     mean_test_accuracy_score param_max_depth param_max_features  \\\n",
       "302                     0.724              25                 17   \n",
       "282                     0.716              25                 10   \n",
       "283                     0.719              25                 10   \n",
       "307                     0.718              25                 17   \n",
       "305                     0.711              25                 17   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \n",
       "302                       2                200  \n",
       "282                       2                200  \n",
       "283                       2                400  \n",
       "307                       5                400  \n",
       "305                       5                100  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results.to_csv('tuning reports/rf_tuning.csv')\n",
    "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n",
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'param_max_depth', 'param_max_features', 'param_min_samples_split', 'param_n_estimators']].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
