{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outperf vs index 1m</th>\n",
       "      <th>outperf vs index 3m</th>\n",
       "      <th>ST momentum</th>\n",
       "      <th>LT momentum</th>\n",
       "      <th>Index vs max</th>\n",
       "      <th>Index st momentum</th>\n",
       "      <th>ebit vs peak</th>\n",
       "      <th>net income vs peak</th>\n",
       "      <th>market cap vs peak</th>\n",
       "      <th>Margin vs peak</th>\n",
       "      <th>PE</th>\n",
       "      <th>xEbit</th>\n",
       "      <th>xSales</th>\n",
       "      <th>PE vs peak</th>\n",
       "      <th>xEbit vs peak</th>\n",
       "      <th>xSales vs peak</th>\n",
       "      <th>ND/market cap</th>\n",
       "      <th>outperf next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.142054</td>\n",
       "      <td>-0.024754</td>\n",
       "      <td>-0.026957</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.046248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.164666</td>\n",
       "      <td>4.258310</td>\n",
       "      <td>0.201669</td>\n",
       "      <td>-0.222973</td>\n",
       "      <td>-0.241666</td>\n",
       "      <td>-0.077194</td>\n",
       "      <td>-0.420316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034843</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>0.428953</td>\n",
       "      <td>0.278566</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.338716</td>\n",
       "      <td>3.232125</td>\n",
       "      <td>0.228630</td>\n",
       "      <td>-0.560311</td>\n",
       "      <td>-0.339660</td>\n",
       "      <td>-0.170085</td>\n",
       "      <td>-0.291897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005101</td>\n",
       "      <td>-0.262568</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>-0.078449</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>-1.518357</td>\n",
       "      <td>-1.629189</td>\n",
       "      <td>-0.228261</td>\n",
       "      <td>-1.569135</td>\n",
       "      <td>-19.416503</td>\n",
       "      <td>-15.838593</td>\n",
       "      <td>0.439608</td>\n",
       "      <td>-2.239239</td>\n",
       "      <td>-2.485813</td>\n",
       "      <td>-0.282300</td>\n",
       "      <td>-0.248044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009696</td>\n",
       "      <td>-0.052876</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.161043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.027157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.273615</td>\n",
       "      <td>13.099569</td>\n",
       "      <td>2.075199</td>\n",
       "      <td>-0.087932</td>\n",
       "      <td>-0.099589</td>\n",
       "      <td>-0.083936</td>\n",
       "      <td>-0.146034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011575</td>\n",
       "      <td>-0.134856</td>\n",
       "      <td>0.118982</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.850217</td>\n",
       "      <td>10.389390</td>\n",
       "      <td>2.263279</td>\n",
       "      <td>-0.102874</td>\n",
       "      <td>-0.268257</td>\n",
       "      <td>-0.223040</td>\n",
       "      <td>-0.021275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outperf vs index 1m  outperf vs index 3m  ST momentum  LT momentum  \\\n",
       "0             0.002703             0.142054    -0.024754    -0.026957   \n",
       "1            -0.034843            -0.099532     0.428953     0.278566   \n",
       "2            -0.005101            -0.262568    -0.014076    -0.078449   \n",
       "3             0.009696            -0.052876     0.075785     0.161043   \n",
       "4             0.011575            -0.134856     0.118982     0.216946   \n",
       "\n",
       "   Index vs max  Index st momentum  ebit vs peak  net income vs peak  \\\n",
       "0          -0.2           0.017742      0.000000            0.000000   \n",
       "1          -0.2           0.017742      0.000000            0.000000   \n",
       "2          -0.2           0.017742     -1.518357           -1.629189   \n",
       "3           0.0           0.017742      0.000000            0.000000   \n",
       "4          -0.2           0.017742      0.000000            0.000000   \n",
       "\n",
       "   market cap vs peak  Margin vs peak         PE      xEbit    xSales  \\\n",
       "0           -0.046248        0.000000   8.164666   4.258310  0.201669   \n",
       "1           -0.035664        0.000000   3.338716   3.232125  0.228630   \n",
       "2           -0.228261       -1.569135 -19.416503 -15.838593  0.439608   \n",
       "3           -0.027157        0.000000  20.273615  13.099569  2.075199   \n",
       "4           -0.093110        0.000000  17.850217  10.389390  2.263279   \n",
       "\n",
       "   PE vs peak  xEbit vs peak  xSales vs peak  ND/market cap  \\\n",
       "0   -0.222973      -0.241666       -0.077194      -0.420316   \n",
       "1   -0.560311      -0.339660       -0.170085      -0.291897   \n",
       "2   -2.239239      -2.485813       -0.282300      -0.248044   \n",
       "3   -0.087932      -0.099589       -0.083936      -0.146034   \n",
       "4   -0.102874      -0.268257       -0.223040      -0.021275   \n",
       "\n",
       "   outperf next month  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('databases/rf_Database_2_training.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process database\n",
    "import numpy as np\n",
    "\n",
    "#save labels\n",
    "labels = np.array(features['outperf next month'])\n",
    "#remove labels\n",
    "features=features.drop('outperf next month', axis = 1)\n",
    "#save features names\n",
    "feature_list = list(features.columns)\n",
    "#convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split database in training and cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2267, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#stratify = labels allows for consistant class distribution between sets\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(features, labels, stratify = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Show distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ones in train set is 0.36082928981032203\n",
      "Percentage of ones in cv set is 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "train_zeros = (y_train == 0).sum()\n",
    "train_ones = (y_train == 1).sum()\n",
    "train_pct = train_ones / (train_zeros + train_ones)\n",
    "print('Percentage of ones in train set is', train_pct )\n",
    "\n",
    "cv_zeros = (y_cv == 0).sum()\n",
    "cv_ones = (y_cv == 1).sum()\n",
    "cv_pct = cv_ones / (cv_zeros + cv_ones)\n",
    "print('Percentage of ones in cv set is', cv_pct )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 20, 40], \n",
    "    'n_estimators' : [50, 100, 200, 400],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 17]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def grid_search_wrapper(refit_score='recall_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_cv)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the cv data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the cv data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_cv, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recall_score\n",
      "{'max_depth': 25, 'max_features': 17, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for recall_score on the cv data:\n",
      "     pred_neg  pred_pos\n",
      "neg       392        91\n",
      "pos       205        68\n"
     ]
    }
   ],
   "source": [
    "grid_search_clf = grid_search_wrapper(refit_score='recall_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.377</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.581</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.373</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.582</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.381</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.586</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.373</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.582</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.580</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_precision_score  mean_test_recall_score  \\\n",
       "304                      0.377                   0.237   \n",
       "240                      0.373                   0.230   \n",
       "281                      0.381                   0.230   \n",
       "284                      0.373                   0.229   \n",
       "260                      0.371                   0.227   \n",
       "\n",
       "     mean_test_accuracy_score param_max_depth param_max_features  \\\n",
       "304                     0.581              25                 17   \n",
       "240                     0.582              25                  3   \n",
       "281                     0.586              25                 10   \n",
       "284                     0.582              25                 10   \n",
       "260                     0.580              25                  5   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \n",
       "304                       5                 50  \n",
       "240                       2                 50  \n",
       "281                       2                100  \n",
       "284                       5                 50  \n",
       "260                       2                 50  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "results.to_csv('tuning reports/rf_tuning.csv')\n",
    "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n",
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'param_max_depth', 'param_max_features', 'param_min_samples_split', 'param_n_estimators']].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
