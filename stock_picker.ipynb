{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.functions import import_data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X train also contains cross validation set. model.fit will split it between training and cross validation\n",
    "X_train, X_test, y_train, y_test = import_data('Database.csv')\n",
    "#convert labels to one-hot vectors\n",
    "y_train_oneHot = keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_oneHot = keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=24,kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.00)))\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.00)))\n",
    "model.add(Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.00)))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001, beta_1 = 0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48 samples, validate on 17 samples\n",
      "Epoch 1/1000\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 3.5049 - acc: 0.2083 - val_loss: 2.5728 - val_acc: 0.2353\n",
      "Epoch 2/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 2.3461 - acc: 0.3333 - val_loss: 2.0802 - val_acc: 0.5882\n",
      "Epoch 3/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 2.0080 - acc: 0.4792 - val_loss: 1.8760 - val_acc: 0.6471\n",
      "Epoch 4/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.9669 - acc: 0.5417 - val_loss: 1.8435 - val_acc: 0.7059\n",
      "Epoch 5/1000\n",
      "48/48 [==============================] - 0s 125us/step - loss: 2.0434 - acc: 0.5833 - val_loss: 1.8708 - val_acc: 0.5882\n",
      "Epoch 6/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 2.0668 - acc: 0.5625 - val_loss: 1.8231 - val_acc: 0.7059\n",
      "Epoch 7/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.9863 - acc: 0.5625 - val_loss: 1.7646 - val_acc: 0.7059\n",
      "Epoch 8/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.8985 - acc: 0.6042 - val_loss: 1.7397 - val_acc: 0.7059\n",
      "Epoch 9/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.8186 - acc: 0.6458 - val_loss: 1.7080 - val_acc: 0.7059\n",
      "Epoch 10/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.7498 - acc: 0.6250 - val_loss: 1.6883 - val_acc: 0.7059\n",
      "Epoch 11/1000\n",
      "48/48 [==============================] - 0s 146us/step - loss: 1.7086 - acc: 0.6458 - val_loss: 1.6927 - val_acc: 0.7059\n",
      "Epoch 12/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.7043 - acc: 0.6458 - val_loss: 1.7124 - val_acc: 0.7647\n",
      "Epoch 13/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.7084 - acc: 0.6042 - val_loss: 1.7084 - val_acc: 0.6471\n",
      "Epoch 14/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 1.6932 - acc: 0.6042 - val_loss: 1.6636 - val_acc: 0.6471\n",
      "Epoch 15/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.6562 - acc: 0.6458 - val_loss: 1.6197 - val_acc: 0.7647\n",
      "Epoch 16/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.6209 - acc: 0.6458 - val_loss: 1.6002 - val_acc: 0.7647\n",
      "Epoch 17/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.6148 - acc: 0.6458 - val_loss: 1.5915 - val_acc: 0.7059\n",
      "Epoch 18/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.6092 - acc: 0.6667 - val_loss: 1.5874 - val_acc: 0.7059\n",
      "Epoch 19/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5974 - acc: 0.6458 - val_loss: 1.5787 - val_acc: 0.7059\n",
      "Epoch 20/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5827 - acc: 0.6250 - val_loss: 1.5673 - val_acc: 0.7059\n",
      "Epoch 21/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.5566 - acc: 0.6458 - val_loss: 1.5664 - val_acc: 0.7059\n",
      "Epoch 22/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.5424 - acc: 0.6667 - val_loss: 1.5783 - val_acc: 0.6471\n",
      "Epoch 23/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.5427 - acc: 0.6875 - val_loss: 1.5935 - val_acc: 0.7059\n",
      "Epoch 24/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5295 - acc: 0.6667 - val_loss: 1.5793 - val_acc: 0.7059\n",
      "Epoch 25/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5201 - acc: 0.6667 - val_loss: 1.5618 - val_acc: 0.6471\n",
      "Epoch 26/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5114 - acc: 0.6667 - val_loss: 1.5374 - val_acc: 0.6471\n",
      "Epoch 27/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.5017 - acc: 0.6458 - val_loss: 1.5250 - val_acc: 0.6471\n",
      "Epoch 28/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4861 - acc: 0.6667 - val_loss: 1.5201 - val_acc: 0.6471\n",
      "Epoch 29/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.4783 - acc: 0.6667 - val_loss: 1.5201 - val_acc: 0.6471\n",
      "Epoch 30/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4662 - acc: 0.6875 - val_loss: 1.5222 - val_acc: 0.7059\n",
      "Epoch 31/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4690 - acc: 0.6458 - val_loss: 1.5242 - val_acc: 0.7059\n",
      "Epoch 32/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.4624 - acc: 0.6458 - val_loss: 1.5136 - val_acc: 0.7059\n",
      "Epoch 33/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.4373 - acc: 0.6875 - val_loss: 1.4889 - val_acc: 0.6471\n",
      "Epoch 34/1000\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5778 - acc: 0.560 - 0s 83us/step - loss: 1.4374 - acc: 0.6458 - val_loss: 1.4763 - val_acc: 0.6471\n",
      "Epoch 35/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4337 - acc: 0.6458 - val_loss: 1.4697 - val_acc: 0.6471\n",
      "Epoch 36/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.4198 - acc: 0.6667 - val_loss: 1.4696 - val_acc: 0.6471\n",
      "Epoch 37/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4097 - acc: 0.6667 - val_loss: 1.4782 - val_acc: 0.7059\n",
      "Epoch 38/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.4076 - acc: 0.6667 - val_loss: 1.4822 - val_acc: 0.7059\n",
      "Epoch 39/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3968 - acc: 0.6667 - val_loss: 1.4659 - val_acc: 0.7059\n",
      "Epoch 40/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3914 - acc: 0.6875 - val_loss: 1.4453 - val_acc: 0.6471\n",
      "Epoch 41/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3817 - acc: 0.6667 - val_loss: 1.4371 - val_acc: 0.6471\n",
      "Epoch 42/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3760 - acc: 0.6458 - val_loss: 1.4351 - val_acc: 0.6471\n",
      "Epoch 43/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3633 - acc: 0.6667 - val_loss: 1.4427 - val_acc: 0.6471\n",
      "Epoch 44/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3570 - acc: 0.6667 - val_loss: 1.4475 - val_acc: 0.7059\n",
      "Epoch 45/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3528 - acc: 0.6875 - val_loss: 1.4455 - val_acc: 0.7059\n",
      "Epoch 46/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3464 - acc: 0.6875 - val_loss: 1.4414 - val_acc: 0.7059\n",
      "Epoch 47/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3414 - acc: 0.6458 - val_loss: 1.4245 - val_acc: 0.6471\n",
      "Epoch 48/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3298 - acc: 0.6667 - val_loss: 1.4122 - val_acc: 0.6471\n",
      "Epoch 49/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3278 - acc: 0.6667 - val_loss: 1.4071 - val_acc: 0.6471\n",
      "Epoch 50/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3167 - acc: 0.6667 - val_loss: 1.3988 - val_acc: 0.6471\n",
      "Epoch 51/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3124 - acc: 0.6667 - val_loss: 1.3927 - val_acc: 0.6471\n",
      "Epoch 52/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.3077 - acc: 0.6667 - val_loss: 1.3901 - val_acc: 0.6471\n",
      "Epoch 53/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.3030 - acc: 0.6667 - val_loss: 1.3871 - val_acc: 0.6471\n",
      "Epoch 54/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2941 - acc: 0.6667 - val_loss: 1.3883 - val_acc: 0.6471\n",
      "Epoch 55/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2977 - acc: 0.6667 - val_loss: 1.4007 - val_acc: 0.7059\n",
      "Epoch 56/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2864 - acc: 0.6458 - val_loss: 1.3918 - val_acc: 0.6471\n",
      "Epoch 57/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2786 - acc: 0.6458 - val_loss: 1.3881 - val_acc: 0.6471\n",
      "Epoch 58/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2757 - acc: 0.6458 - val_loss: 1.3828 - val_acc: 0.6471\n",
      "Epoch 59/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2663 - acc: 0.6458 - val_loss: 1.3686 - val_acc: 0.6471\n",
      "Epoch 60/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2745 - acc: 0.6667 - val_loss: 1.3543 - val_acc: 0.6471\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 63us/step - loss: 1.2580 - acc: 0.6667 - val_loss: 1.3562 - val_acc: 0.6471\n",
      "Epoch 62/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.2517 - acc: 0.6667 - val_loss: 1.3595 - val_acc: 0.6471\n",
      "Epoch 63/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2485 - acc: 0.6875 - val_loss: 1.3615 - val_acc: 0.6471\n",
      "Epoch 64/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2416 - acc: 0.6875 - val_loss: 1.3657 - val_acc: 0.6471\n",
      "Epoch 65/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2429 - acc: 0.6667 - val_loss: 1.3554 - val_acc: 0.6471\n",
      "Epoch 66/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2355 - acc: 0.6667 - val_loss: 1.3586 - val_acc: 0.6471\n",
      "Epoch 67/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2318 - acc: 0.6667 - val_loss: 1.3483 - val_acc: 0.6471\n",
      "Epoch 68/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2271 - acc: 0.6667 - val_loss: 1.3408 - val_acc: 0.6471\n",
      "Epoch 69/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2170 - acc: 0.6667 - val_loss: 1.3427 - val_acc: 0.6471\n",
      "Epoch 70/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2144 - acc: 0.7083 - val_loss: 1.3425 - val_acc: 0.7059\n",
      "Epoch 71/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2125 - acc: 0.7083 - val_loss: 1.3386 - val_acc: 0.7059\n",
      "Epoch 72/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.2072 - acc: 0.7083 - val_loss: 1.3267 - val_acc: 0.6471\n",
      "Epoch 73/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.2025 - acc: 0.6667 - val_loss: 1.3180 - val_acc: 0.6471\n",
      "Epoch 74/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1980 - acc: 0.6667 - val_loss: 1.3137 - val_acc: 0.6471\n",
      "Epoch 75/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1948 - acc: 0.6667 - val_loss: 1.3132 - val_acc: 0.6471\n",
      "Epoch 76/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1969 - acc: 0.6667 - val_loss: 1.3237 - val_acc: 0.6471\n",
      "Epoch 77/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1856 - acc: 0.6667 - val_loss: 1.3163 - val_acc: 0.6471\n",
      "Epoch 78/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.1829 - acc: 0.6875 - val_loss: 1.3143 - val_acc: 0.6471\n",
      "Epoch 79/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.1889 - acc: 0.7083 - val_loss: 1.3080 - val_acc: 0.6471\n",
      "Epoch 80/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.1803 - acc: 0.6875 - val_loss: 1.2938 - val_acc: 0.6471\n",
      "Epoch 81/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1760 - acc: 0.6667 - val_loss: 1.2946 - val_acc: 0.6471\n",
      "Epoch 82/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1706 - acc: 0.6667 - val_loss: 1.2952 - val_acc: 0.6471\n",
      "Epoch 83/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1636 - acc: 0.6667 - val_loss: 1.3013 - val_acc: 0.6471\n",
      "Epoch 84/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1613 - acc: 0.6875 - val_loss: 1.3100 - val_acc: 0.7059\n",
      "Epoch 85/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1587 - acc: 0.6875 - val_loss: 1.3081 - val_acc: 0.7059\n",
      "Epoch 86/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1545 - acc: 0.6875 - val_loss: 1.2954 - val_acc: 0.6471\n",
      "Epoch 87/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1521 - acc: 0.6667 - val_loss: 1.2819 - val_acc: 0.6471\n",
      "Epoch 88/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1599 - acc: 0.6667 - val_loss: 1.2758 - val_acc: 0.6471\n",
      "Epoch 89/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 1.1488 - acc: 0.6875 - val_loss: 1.2851 - val_acc: 0.6471\n",
      "Epoch 90/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1461 - acc: 0.7083 - val_loss: 1.2987 - val_acc: 0.7059\n",
      "Epoch 91/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1404 - acc: 0.7083 - val_loss: 1.2905 - val_acc: 0.6471\n",
      "Epoch 92/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1408 - acc: 0.6875 - val_loss: 1.2900 - val_acc: 0.6471\n",
      "Epoch 93/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1438 - acc: 0.6458 - val_loss: 1.2725 - val_acc: 0.6471\n",
      "Epoch 94/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1338 - acc: 0.6667 - val_loss: 1.2710 - val_acc: 0.6471\n",
      "Epoch 95/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1287 - acc: 0.6458 - val_loss: 1.2763 - val_acc: 0.6471\n",
      "Epoch 96/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1216 - acc: 0.6875 - val_loss: 1.2798 - val_acc: 0.6471\n",
      "Epoch 97/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1212 - acc: 0.6875 - val_loss: 1.2828 - val_acc: 0.6471\n",
      "Epoch 98/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1189 - acc: 0.7083 - val_loss: 1.2748 - val_acc: 0.6471\n",
      "Epoch 99/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1252 - acc: 0.6875 - val_loss: 1.2582 - val_acc: 0.6471\n",
      "Epoch 100/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1172 - acc: 0.6875 - val_loss: 1.2591 - val_acc: 0.6471\n",
      "Epoch 101/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1088 - acc: 0.6458 - val_loss: 1.2740 - val_acc: 0.6471\n",
      "Epoch 102/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1117 - acc: 0.6458 - val_loss: 1.2806 - val_acc: 0.7059\n",
      "Epoch 103/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1077 - acc: 0.6875 - val_loss: 1.2675 - val_acc: 0.6471\n",
      "Epoch 104/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.1130 - acc: 0.6667 - val_loss: 1.2550 - val_acc: 0.6471\n",
      "Epoch 105/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1009 - acc: 0.6458 - val_loss: 1.2548 - val_acc: 0.6471\n",
      "Epoch 106/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1028 - acc: 0.6667 - val_loss: 1.2494 - val_acc: 0.6471\n",
      "Epoch 107/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0953 - acc: 0.6875 - val_loss: 1.2562 - val_acc: 0.6471\n",
      "Epoch 108/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0961 - acc: 0.6875 - val_loss: 1.2594 - val_acc: 0.6471\n",
      "Epoch 109/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0920 - acc: 0.6875 - val_loss: 1.2451 - val_acc: 0.6471\n",
      "Epoch 110/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0876 - acc: 0.6875 - val_loss: 1.2434 - val_acc: 0.6471\n",
      "Epoch 111/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.1081 - acc: 0.6667 - val_loss: 1.2409 - val_acc: 0.6471\n",
      "Epoch 112/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0817 - acc: 0.6458 - val_loss: 1.2603 - val_acc: 0.7059\n",
      "Epoch 113/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0817 - acc: 0.6667 - val_loss: 1.2722 - val_acc: 0.7059\n",
      "Epoch 114/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0843 - acc: 0.6875 - val_loss: 1.2617 - val_acc: 0.7059\n",
      "Epoch 115/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0808 - acc: 0.6875 - val_loss: 1.2379 - val_acc: 0.6471\n",
      "Epoch 116/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0766 - acc: 0.6667 - val_loss: 1.2340 - val_acc: 0.6471\n",
      "Epoch 117/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0830 - acc: 0.6458 - val_loss: 1.2413 - val_acc: 0.6471\n",
      "Epoch 118/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0696 - acc: 0.6458 - val_loss: 1.2393 - val_acc: 0.6471\n",
      "Epoch 119/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0678 - acc: 0.6875 - val_loss: 1.2403 - val_acc: 0.6471\n",
      "Epoch 120/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0675 - acc: 0.6875 - val_loss: 1.2364 - val_acc: 0.6471\n",
      "Epoch 121/1000\n",
      "48/48 [==============================] - 0s 82us/step - loss: 1.0663 - acc: 0.6875 - val_loss: 1.2317 - val_acc: 0.6471\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 83us/step - loss: 1.0666 - acc: 0.6875 - val_loss: 1.2276 - val_acc: 0.6471\n",
      "Epoch 123/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0638 - acc: 0.6875 - val_loss: 1.2398 - val_acc: 0.6471\n",
      "Epoch 124/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0609 - acc: 0.6667 - val_loss: 1.2387 - val_acc: 0.6471\n",
      "Epoch 125/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0564 - acc: 0.6458 - val_loss: 1.2407 - val_acc: 0.6471\n",
      "Epoch 126/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0558 - acc: 0.6458 - val_loss: 1.2354 - val_acc: 0.6471\n",
      "Epoch 127/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0530 - acc: 0.6458 - val_loss: 1.2277 - val_acc: 0.6471\n",
      "Epoch 128/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0526 - acc: 0.6667 - val_loss: 1.2232 - val_acc: 0.6471\n",
      "Epoch 129/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 1.0513 - acc: 0.6875 - val_loss: 1.2237 - val_acc: 0.6471\n",
      "Epoch 130/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0552 - acc: 0.6875 - val_loss: 1.2260 - val_acc: 0.6471\n",
      "Epoch 131/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0511 - acc: 0.6667 - val_loss: 1.2392 - val_acc: 0.6471\n",
      "Epoch 132/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.0568 - acc: 0.6458 - val_loss: 1.2443 - val_acc: 0.7059\n",
      "Epoch 133/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0449 - acc: 0.6458 - val_loss: 1.2224 - val_acc: 0.6471\n",
      "Epoch 134/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0441 - acc: 0.6667 - val_loss: 1.2120 - val_acc: 0.6471\n",
      "Epoch 135/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0450 - acc: 0.6875 - val_loss: 1.2166 - val_acc: 0.6471\n",
      "Epoch 136/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0396 - acc: 0.6875 - val_loss: 1.2335 - val_acc: 0.6471\n",
      "Epoch 137/1000\n",
      "48/48 [==============================] - 0s 84us/step - loss: 1.0408 - acc: 0.6875 - val_loss: 1.2363 - val_acc: 0.6471\n",
      "Epoch 138/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0349 - acc: 0.6667 - val_loss: 1.2354 - val_acc: 0.6471\n",
      "Epoch 139/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0320 - acc: 0.6667 - val_loss: 1.2274 - val_acc: 0.6471\n",
      "Epoch 140/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0301 - acc: 0.6667 - val_loss: 1.2186 - val_acc: 0.6471\n",
      "Epoch 141/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0284 - acc: 0.6458 - val_loss: 1.2112 - val_acc: 0.6471\n",
      "Epoch 142/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0268 - acc: 0.6875 - val_loss: 1.2081 - val_acc: 0.6471\n",
      "Epoch 143/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0267 - acc: 0.6875 - val_loss: 1.2133 - val_acc: 0.6471\n",
      "Epoch 144/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0238 - acc: 0.6875 - val_loss: 1.2206 - val_acc: 0.6471\n",
      "Epoch 145/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0284 - acc: 0.6875 - val_loss: 1.2282 - val_acc: 0.6471\n",
      "Epoch 146/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0225 - acc: 0.6667 - val_loss: 1.2163 - val_acc: 0.6471\n",
      "Epoch 147/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0262 - acc: 0.6458 - val_loss: 1.2173 - val_acc: 0.6471\n",
      "Epoch 148/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0214 - acc: 0.6458 - val_loss: 1.2073 - val_acc: 0.6471\n",
      "Epoch 149/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0229 - acc: 0.6667 - val_loss: 1.2113 - val_acc: 0.6471\n",
      "Epoch 150/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0252 - acc: 0.6667 - val_loss: 1.2188 - val_acc: 0.6471\n",
      "Epoch 151/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.0167 - acc: 0.6667 - val_loss: 1.2173 - val_acc: 0.6471\n",
      "Epoch 152/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0129 - acc: 0.6667 - val_loss: 1.2057 - val_acc: 0.6471\n",
      "Epoch 153/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0107 - acc: 0.6875 - val_loss: 1.1994 - val_acc: 0.6471\n",
      "Epoch 154/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0113 - acc: 0.7083 - val_loss: 1.1986 - val_acc: 0.6471\n",
      "Epoch 155/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0122 - acc: 0.6875 - val_loss: 1.2080 - val_acc: 0.6471\n",
      "Epoch 156/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0071 - acc: 0.6667 - val_loss: 1.2112 - val_acc: 0.6471\n",
      "Epoch 157/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.0053 - acc: 0.6875 - val_loss: 1.2090 - val_acc: 0.6471\n",
      "Epoch 158/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 1.0074 - acc: 0.6875 - val_loss: 1.2080 - val_acc: 0.6471\n",
      "Epoch 159/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0015 - acc: 0.6875 - val_loss: 1.2151 - val_acc: 0.6471\n",
      "Epoch 160/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0117 - acc: 0.7083 - val_loss: 1.2189 - val_acc: 0.6471\n",
      "Epoch 161/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 1.0031 - acc: 0.7083 - val_loss: 1.2082 - val_acc: 0.6471\n",
      "Epoch 162/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9988 - acc: 0.6458 - val_loss: 1.2090 - val_acc: 0.6471\n",
      "Epoch 163/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 1.0020 - acc: 0.6875 - val_loss: 1.2071 - val_acc: 0.6471\n",
      "Epoch 164/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9971 - acc: 0.6875 - val_loss: 1.2023 - val_acc: 0.6471\n",
      "Epoch 165/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9996 - acc: 0.6875 - val_loss: 1.2003 - val_acc: 0.6471\n",
      "Epoch 166/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9915 - acc: 0.6667 - val_loss: 1.2135 - val_acc: 0.6471\n",
      "Epoch 167/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9982 - acc: 0.7083 - val_loss: 1.2245 - val_acc: 0.7059\n",
      "Epoch 168/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9951 - acc: 0.7083 - val_loss: 1.2104 - val_acc: 0.6471\n",
      "Epoch 169/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.9922 - acc: 0.6875 - val_loss: 1.1992 - val_acc: 0.6471\n",
      "Epoch 170/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 0.9881 - acc: 0.6875 - val_loss: 1.2048 - val_acc: 0.6471\n",
      "Epoch 171/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9864 - acc: 0.6875 - val_loss: 1.2120 - val_acc: 0.6471\n",
      "Epoch 172/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9843 - acc: 0.7083 - val_loss: 1.2191 - val_acc: 0.6471\n",
      "Epoch 173/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9837 - acc: 0.6667 - val_loss: 1.2070 - val_acc: 0.6471\n",
      "Epoch 174/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9868 - acc: 0.6875 - val_loss: 1.2040 - val_acc: 0.6471\n",
      "Epoch 175/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9809 - acc: 0.7083 - val_loss: 1.1995 - val_acc: 0.6471\n",
      "Epoch 176/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9924 - acc: 0.6875 - val_loss: 1.2102 - val_acc: 0.5882\n",
      "Epoch 177/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9798 - acc: 0.7083 - val_loss: 1.2121 - val_acc: 0.6471\n",
      "Epoch 178/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9910 - acc: 0.6667 - val_loss: 1.2221 - val_acc: 0.7059\n",
      "Epoch 179/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9810 - acc: 0.7083 - val_loss: 1.2001 - val_acc: 0.6471\n",
      "Epoch 180/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9783 - acc: 0.6875 - val_loss: 1.1968 - val_acc: 0.5882\n",
      "Epoch 181/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9772 - acc: 0.6875 - val_loss: 1.2052 - val_acc: 0.5882\n",
      "Epoch 182/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9730 - acc: 0.6875 - val_loss: 1.2067 - val_acc: 0.6471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9688 - acc: 0.7083 - val_loss: 1.2171 - val_acc: 0.6471\n",
      "Epoch 184/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9711 - acc: 0.6875 - val_loss: 1.2164 - val_acc: 0.6471\n",
      "Epoch 185/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9688 - acc: 0.6875 - val_loss: 1.2074 - val_acc: 0.5882\n",
      "Epoch 186/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9663 - acc: 0.7083 - val_loss: 1.1941 - val_acc: 0.6471\n",
      "Epoch 187/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9670 - acc: 0.6875 - val_loss: 1.1948 - val_acc: 0.6471\n",
      "Epoch 188/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9699 - acc: 0.7083 - val_loss: 1.2122 - val_acc: 0.6471\n",
      "Epoch 189/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9603 - acc: 0.7083 - val_loss: 1.2109 - val_acc: 0.5882\n",
      "Epoch 190/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9598 - acc: 0.7292 - val_loss: 1.2083 - val_acc: 0.5882\n",
      "Epoch 191/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9681 - acc: 0.7083 - val_loss: 1.2126 - val_acc: 0.6471\n",
      "Epoch 192/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9591 - acc: 0.7292 - val_loss: 1.1998 - val_acc: 0.5882\n",
      "Epoch 193/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9583 - acc: 0.7083 - val_loss: 1.2031 - val_acc: 0.5882\n",
      "Epoch 194/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9613 - acc: 0.7292 - val_loss: 1.1953 - val_acc: 0.6471\n",
      "Epoch 195/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9535 - acc: 0.7083 - val_loss: 1.2090 - val_acc: 0.5882\n",
      "Epoch 196/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9499 - acc: 0.7292 - val_loss: 1.2166 - val_acc: 0.5882\n",
      "Epoch 197/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9501 - acc: 0.7292 - val_loss: 1.2109 - val_acc: 0.5882\n",
      "Epoch 198/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9496 - acc: 0.7292 - val_loss: 1.2066 - val_acc: 0.5882\n",
      "Epoch 199/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9462 - acc: 0.7292 - val_loss: 1.1989 - val_acc: 0.5882\n",
      "Epoch 200/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9581 - acc: 0.7083 - val_loss: 1.1980 - val_acc: 0.5882\n",
      "Epoch 201/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9589 - acc: 0.7083 - val_loss: 1.2219 - val_acc: 0.5882\n",
      "Epoch 202/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9569 - acc: 0.7083 - val_loss: 1.2210 - val_acc: 0.5882\n",
      "Epoch 203/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9456 - acc: 0.6875 - val_loss: 1.1972 - val_acc: 0.5882\n",
      "Epoch 204/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9465 - acc: 0.7083 - val_loss: 1.1925 - val_acc: 0.5882\n",
      "Epoch 205/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9416 - acc: 0.7292 - val_loss: 1.2053 - val_acc: 0.5882\n",
      "Epoch 206/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9392 - acc: 0.7500 - val_loss: 1.2286 - val_acc: 0.5882\n",
      "Epoch 207/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9453 - acc: 0.7292 - val_loss: 1.2141 - val_acc: 0.5882\n",
      "Epoch 208/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9356 - acc: 0.7292 - val_loss: 1.2107 - val_acc: 0.5882\n",
      "Epoch 209/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.9359 - acc: 0.7292 - val_loss: 1.2086 - val_acc: 0.5882\n",
      "Epoch 210/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9371 - acc: 0.7500 - val_loss: 1.2216 - val_acc: 0.5882\n",
      "Epoch 211/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9312 - acc: 0.7292 - val_loss: 1.2070 - val_acc: 0.5882\n",
      "Epoch 212/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9310 - acc: 0.7708 - val_loss: 1.2041 - val_acc: 0.5882\n",
      "Epoch 213/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9350 - acc: 0.7083 - val_loss: 1.2005 - val_acc: 0.5882\n",
      "Epoch 214/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9282 - acc: 0.7292 - val_loss: 1.2124 - val_acc: 0.5882\n",
      "Epoch 215/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9275 - acc: 0.7292 - val_loss: 1.2173 - val_acc: 0.5882\n",
      "Epoch 216/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.9246 - acc: 0.7500 - val_loss: 1.2076 - val_acc: 0.5882\n",
      "Epoch 217/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9257 - acc: 0.7500 - val_loss: 1.1986 - val_acc: 0.5882\n",
      "Epoch 218/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9220 - acc: 0.7292 - val_loss: 1.2020 - val_acc: 0.5882\n",
      "Epoch 219/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9190 - acc: 0.7500 - val_loss: 1.2146 - val_acc: 0.5882\n",
      "Epoch 220/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9275 - acc: 0.7083 - val_loss: 1.2140 - val_acc: 0.5882\n",
      "Epoch 221/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9219 - acc: 0.7083 - val_loss: 1.2190 - val_acc: 0.5882\n",
      "Epoch 222/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9214 - acc: 0.7500 - val_loss: 1.2089 - val_acc: 0.5882\n",
      "Epoch 223/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9229 - acc: 0.7292 - val_loss: 1.2013 - val_acc: 0.5882\n",
      "Epoch 224/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9212 - acc: 0.7500 - val_loss: 1.2071 - val_acc: 0.5882\n",
      "Epoch 225/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9347 - acc: 0.7083 - val_loss: 1.2289 - val_acc: 0.5882\n",
      "Epoch 226/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9161 - acc: 0.7083 - val_loss: 1.2249 - val_acc: 0.5882\n",
      "Epoch 227/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9156 - acc: 0.7292 - val_loss: 1.1980 - val_acc: 0.5882\n",
      "Epoch 228/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9113 - acc: 0.7292 - val_loss: 1.1994 - val_acc: 0.5882\n",
      "Epoch 229/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9159 - acc: 0.7917 - val_loss: 1.2204 - val_acc: 0.5882\n",
      "Epoch 230/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9105 - acc: 0.7708 - val_loss: 1.2266 - val_acc: 0.5882\n",
      "Epoch 231/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9105 - acc: 0.7708 - val_loss: 1.2210 - val_acc: 0.5882\n",
      "Epoch 232/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9029 - acc: 0.7500 - val_loss: 1.2091 - val_acc: 0.5882\n",
      "Epoch 233/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9008 - acc: 0.7500 - val_loss: 1.2040 - val_acc: 0.5882\n",
      "Epoch 234/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9011 - acc: 0.7500 - val_loss: 1.2098 - val_acc: 0.5882\n",
      "Epoch 235/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8988 - acc: 0.7708 - val_loss: 1.2279 - val_acc: 0.5882\n",
      "Epoch 236/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9011 - acc: 0.7708 - val_loss: 1.2263 - val_acc: 0.5882\n",
      "Epoch 237/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8974 - acc: 0.7500 - val_loss: 1.2093 - val_acc: 0.5882\n",
      "Epoch 238/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 0.8975 - acc: 0.7500 - val_loss: 1.2106 - val_acc: 0.5882\n",
      "Epoch 239/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9219 - acc: 0.7500 - val_loss: 1.2103 - val_acc: 0.5882\n",
      "Epoch 240/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9145 - acc: 0.7500 - val_loss: 1.2663 - val_acc: 0.5882\n",
      "Epoch 241/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.9115 - acc: 0.7500 - val_loss: 1.2496 - val_acc: 0.5294\n",
      "Epoch 242/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8917 - acc: 0.7917 - val_loss: 1.2036 - val_acc: 0.5882\n",
      "Epoch 243/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 83us/step - loss: 0.8988 - acc: 0.7708 - val_loss: 1.2007 - val_acc: 0.5882\n",
      "Epoch 244/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.9050 - acc: 0.7708 - val_loss: 1.2227 - val_acc: 0.5882\n",
      "Epoch 245/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8913 - acc: 0.7500 - val_loss: 1.2569 - val_acc: 0.5294\n",
      "Epoch 246/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8939 - acc: 0.7292 - val_loss: 1.2392 - val_acc: 0.5882\n",
      "Epoch 247/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8872 - acc: 0.7917 - val_loss: 1.2117 - val_acc: 0.5882\n",
      "Epoch 248/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8873 - acc: 0.7708 - val_loss: 1.2068 - val_acc: 0.5882\n",
      "Epoch 249/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8844 - acc: 0.7708 - val_loss: 1.2227 - val_acc: 0.5882\n",
      "Epoch 250/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8836 - acc: 0.7917 - val_loss: 1.2451 - val_acc: 0.5882\n",
      "Epoch 251/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8828 - acc: 0.7500 - val_loss: 1.2366 - val_acc: 0.5882\n",
      "Epoch 252/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8771 - acc: 0.7708 - val_loss: 1.2192 - val_acc: 0.5882\n",
      "Epoch 253/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8889 - acc: 0.7500 - val_loss: 1.2094 - val_acc: 0.5882\n",
      "Epoch 254/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8806 - acc: 0.7917 - val_loss: 1.2329 - val_acc: 0.5882\n",
      "Epoch 255/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8737 - acc: 0.7917 - val_loss: 1.2486 - val_acc: 0.5294\n",
      "Epoch 256/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8751 - acc: 0.7500 - val_loss: 1.2436 - val_acc: 0.5294\n",
      "Epoch 257/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8796 - acc: 0.7708 - val_loss: 1.2349 - val_acc: 0.5294\n",
      "Epoch 258/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8803 - acc: 0.7500 - val_loss: 1.2134 - val_acc: 0.5882\n",
      "Epoch 259/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8724 - acc: 0.7708 - val_loss: 1.2243 - val_acc: 0.5882\n",
      "Epoch 260/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8685 - acc: 0.7917 - val_loss: 1.2478 - val_acc: 0.5882\n",
      "Epoch 261/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8767 - acc: 0.7708 - val_loss: 1.2575 - val_acc: 0.5294\n",
      "Epoch 262/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8688 - acc: 0.7708 - val_loss: 1.2235 - val_acc: 0.5882\n",
      "Epoch 263/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8668 - acc: 0.7500 - val_loss: 1.2147 - val_acc: 0.5882\n",
      "Epoch 264/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8708 - acc: 0.7708 - val_loss: 1.2254 - val_acc: 0.5882\n",
      "Epoch 265/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8734 - acc: 0.7708 - val_loss: 1.2363 - val_acc: 0.5882\n",
      "Epoch 266/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8645 - acc: 0.7708 - val_loss: 1.2333 - val_acc: 0.5882\n",
      "Epoch 267/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8716 - acc: 0.7708 - val_loss: 1.2473 - val_acc: 0.5294\n",
      "Epoch 268/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8675 - acc: 0.7917 - val_loss: 1.2571 - val_acc: 0.5294\n",
      "Epoch 269/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8633 - acc: 0.7708 - val_loss: 1.2698 - val_acc: 0.5294\n",
      "Epoch 270/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8754 - acc: 0.7708 - val_loss: 1.2375 - val_acc: 0.5882\n",
      "Epoch 271/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8653 - acc: 0.7917 - val_loss: 1.2145 - val_acc: 0.5882\n",
      "Epoch 272/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8687 - acc: 0.7292 - val_loss: 1.2282 - val_acc: 0.5882\n",
      "Epoch 273/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8600 - acc: 0.7500 - val_loss: 1.2630 - val_acc: 0.5294\n",
      "Epoch 274/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8596 - acc: 0.7708 - val_loss: 1.2685 - val_acc: 0.5294\n",
      "Epoch 275/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8547 - acc: 0.7917 - val_loss: 1.2311 - val_acc: 0.5882\n",
      "Epoch 276/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8698 - acc: 0.7917 - val_loss: 1.2137 - val_acc: 0.5882\n",
      "Epoch 277/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8599 - acc: 0.7917 - val_loss: 1.2379 - val_acc: 0.5882\n",
      "Epoch 278/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8533 - acc: 0.7917 - val_loss: 1.2555 - val_acc: 0.5882\n",
      "Epoch 279/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8516 - acc: 0.7708 - val_loss: 1.2447 - val_acc: 0.5294\n",
      "Epoch 280/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8508 - acc: 0.7708 - val_loss: 1.2402 - val_acc: 0.5294\n",
      "Epoch 281/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8455 - acc: 0.7708 - val_loss: 1.2364 - val_acc: 0.5882\n",
      "Epoch 282/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8694 - acc: 0.7917 - val_loss: 1.2476 - val_acc: 0.5882\n",
      "Epoch 283/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8487 - acc: 0.7917 - val_loss: 1.2326 - val_acc: 0.5882\n",
      "Epoch 284/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8443 - acc: 0.7708 - val_loss: 1.2326 - val_acc: 0.5882\n",
      "Epoch 285/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8427 - acc: 0.7708 - val_loss: 1.2450 - val_acc: 0.5882\n",
      "Epoch 286/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8433 - acc: 0.7917 - val_loss: 1.2525 - val_acc: 0.5882\n",
      "Epoch 287/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8427 - acc: 0.7917 - val_loss: 1.2414 - val_acc: 0.5882\n",
      "Epoch 288/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8378 - acc: 0.7708 - val_loss: 1.2290 - val_acc: 0.5882\n",
      "Epoch 289/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8411 - acc: 0.7917 - val_loss: 1.2392 - val_acc: 0.5882\n",
      "Epoch 290/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8408 - acc: 0.7917 - val_loss: 1.2572 - val_acc: 0.5294\n",
      "Epoch 291/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8396 - acc: 0.8125 - val_loss: 1.2790 - val_acc: 0.5294\n",
      "Epoch 292/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8389 - acc: 0.8125 - val_loss: 1.2520 - val_acc: 0.5882\n",
      "Epoch 293/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8492 - acc: 0.7917 - val_loss: 1.2378 - val_acc: 0.5882\n",
      "Epoch 294/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8343 - acc: 0.7917 - val_loss: 1.2579 - val_acc: 0.5882\n",
      "Epoch 295/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8371 - acc: 0.7917 - val_loss: 1.2890 - val_acc: 0.5294\n",
      "Epoch 296/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8473 - acc: 0.7708 - val_loss: 1.2728 - val_acc: 0.5294\n",
      "Epoch 297/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8274 - acc: 0.8125 - val_loss: 1.2341 - val_acc: 0.5882\n",
      "Epoch 298/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8350 - acc: 0.7917 - val_loss: 1.2367 - val_acc: 0.5882\n",
      "Epoch 299/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8367 - acc: 0.7708 - val_loss: 1.2532 - val_acc: 0.5882\n",
      "Epoch 300/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8408 - acc: 0.7917 - val_loss: 1.3038 - val_acc: 0.5294\n",
      "Epoch 301/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8474 - acc: 0.7917 - val_loss: 1.2570 - val_acc: 0.5882\n",
      "Epoch 302/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8314 - acc: 0.7917 - val_loss: 1.2485 - val_acc: 0.5882\n",
      "Epoch 303/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8229 - acc: 0.7917 - val_loss: 1.2501 - val_acc: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8322 - acc: 0.7917 - val_loss: 1.2756 - val_acc: 0.5294\n",
      "Epoch 305/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8272 - acc: 0.8125 - val_loss: 1.2636 - val_acc: 0.5294\n",
      "Epoch 306/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8199 - acc: 0.8125 - val_loss: 1.2422 - val_acc: 0.5882\n",
      "Epoch 307/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8219 - acc: 0.7917 - val_loss: 1.2382 - val_acc: 0.5882\n",
      "Epoch 308/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8205 - acc: 0.8125 - val_loss: 1.2501 - val_acc: 0.5882\n",
      "Epoch 309/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8277 - acc: 0.7917 - val_loss: 1.2748 - val_acc: 0.5294\n",
      "Epoch 310/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8187 - acc: 0.8125 - val_loss: 1.2554 - val_acc: 0.5882\n",
      "Epoch 311/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8170 - acc: 0.8333 - val_loss: 1.2453 - val_acc: 0.5882\n",
      "Epoch 312/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8172 - acc: 0.7708 - val_loss: 1.2611 - val_acc: 0.5882\n",
      "Epoch 313/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8161 - acc: 0.7917 - val_loss: 1.2707 - val_acc: 0.5294\n",
      "Epoch 314/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8136 - acc: 0.7917 - val_loss: 1.2695 - val_acc: 0.5294\n",
      "Epoch 315/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8121 - acc: 0.8333 - val_loss: 1.2672 - val_acc: 0.5294\n",
      "Epoch 316/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.8150 - acc: 0.7917 - val_loss: 1.2560 - val_acc: 0.5882\n",
      "Epoch 317/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8171 - acc: 0.8125 - val_loss: 1.2509 - val_acc: 0.5882\n",
      "Epoch 318/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8176 - acc: 0.8333 - val_loss: 1.2842 - val_acc: 0.5294\n",
      "Epoch 319/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8114 - acc: 0.8333 - val_loss: 1.2729 - val_acc: 0.5294\n",
      "Epoch 320/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8055 - acc: 0.8125 - val_loss: 1.2408 - val_acc: 0.5882\n",
      "Epoch 321/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8340 - acc: 0.7917 - val_loss: 1.2373 - val_acc: 0.5882\n",
      "Epoch 322/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8262 - acc: 0.7917 - val_loss: 1.2947 - val_acc: 0.5294\n",
      "Epoch 323/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8178 - acc: 0.8125 - val_loss: 1.2975 - val_acc: 0.5294\n",
      "Epoch 324/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8111 - acc: 0.7917 - val_loss: 1.2695 - val_acc: 0.5294\n",
      "Epoch 325/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.8000 - acc: 0.8333 - val_loss: 1.2402 - val_acc: 0.5882\n",
      "Epoch 326/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8335 - acc: 0.8125 - val_loss: 1.2386 - val_acc: 0.5882\n",
      "Epoch 327/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8327 - acc: 0.7708 - val_loss: 1.3168 - val_acc: 0.5294\n",
      "Epoch 328/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8207 - acc: 0.7917 - val_loss: 1.3103 - val_acc: 0.5294\n",
      "Epoch 329/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8275 - acc: 0.7917 - val_loss: 1.2631 - val_acc: 0.5882\n",
      "Epoch 330/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8296 - acc: 0.7708 - val_loss: 1.2503 - val_acc: 0.5882\n",
      "Epoch 331/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8023 - acc: 0.7708 - val_loss: 1.2938 - val_acc: 0.5882\n",
      "Epoch 332/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8090 - acc: 0.7917 - val_loss: 1.3124 - val_acc: 0.5294\n",
      "Epoch 333/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.8077 - acc: 0.8333 - val_loss: 1.2895 - val_acc: 0.5294\n",
      "Epoch 334/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7950 - acc: 0.8125 - val_loss: 1.2575 - val_acc: 0.5882\n",
      "Epoch 335/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8098 - acc: 0.8333 - val_loss: 1.2555 - val_acc: 0.5882\n",
      "Epoch 336/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7961 - acc: 0.8125 - val_loss: 1.2777 - val_acc: 0.5882\n",
      "Epoch 337/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7982 - acc: 0.7917 - val_loss: 1.3131 - val_acc: 0.5294\n",
      "Epoch 338/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7951 - acc: 0.8125 - val_loss: 1.2907 - val_acc: 0.5294\n",
      "Epoch 339/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7891 - acc: 0.8333 - val_loss: 1.2686 - val_acc: 0.5294\n",
      "Epoch 340/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7989 - acc: 0.8333 - val_loss: 1.2612 - val_acc: 0.5882\n",
      "Epoch 341/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7880 - acc: 0.8125 - val_loss: 1.2919 - val_acc: 0.5882\n",
      "Epoch 342/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7960 - acc: 0.8125 - val_loss: 1.3169 - val_acc: 0.5294\n",
      "Epoch 343/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7971 - acc: 0.8125 - val_loss: 1.2842 - val_acc: 0.5294\n",
      "Epoch 344/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7890 - acc: 0.8125 - val_loss: 1.2530 - val_acc: 0.5882\n",
      "Epoch 345/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.8001 - acc: 0.8542 - val_loss: 1.2667 - val_acc: 0.5882\n",
      "Epoch 346/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7953 - acc: 0.8125 - val_loss: 1.3103 - val_acc: 0.5294\n",
      "Epoch 347/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7927 - acc: 0.8125 - val_loss: 1.3041 - val_acc: 0.5294\n",
      "Epoch 348/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7806 - acc: 0.8125 - val_loss: 1.2763 - val_acc: 0.5294\n",
      "Epoch 349/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7894 - acc: 0.8750 - val_loss: 1.2640 - val_acc: 0.5882\n",
      "Epoch 350/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7860 - acc: 0.8542 - val_loss: 1.2835 - val_acc: 0.5294\n",
      "Epoch 351/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7997 - acc: 0.8125 - val_loss: 1.3047 - val_acc: 0.5294\n",
      "Epoch 352/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7830 - acc: 0.8125 - val_loss: 1.2679 - val_acc: 0.5882\n",
      "Epoch 353/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7812 - acc: 0.8333 - val_loss: 1.2584 - val_acc: 0.5882\n",
      "Epoch 354/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7850 - acc: 0.8542 - val_loss: 1.2780 - val_acc: 0.5294\n",
      "Epoch 355/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7741 - acc: 0.8333 - val_loss: 1.3148 - val_acc: 0.5294\n",
      "Epoch 356/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7928 - acc: 0.8125 - val_loss: 1.3240 - val_acc: 0.5294\n",
      "Epoch 357/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7963 - acc: 0.8125 - val_loss: 1.2572 - val_acc: 0.5882\n",
      "Epoch 358/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7971 - acc: 0.8125 - val_loss: 1.2563 - val_acc: 0.5882\n",
      "Epoch 359/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7729 - acc: 0.8542 - val_loss: 1.3132 - val_acc: 0.5294\n",
      "Epoch 360/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7850 - acc: 0.8333 - val_loss: 1.3423 - val_acc: 0.4706\n",
      "Epoch 361/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7792 - acc: 0.8125 - val_loss: 1.2792 - val_acc: 0.5294\n",
      "Epoch 362/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7805 - acc: 0.8125 - val_loss: 1.2616 - val_acc: 0.5882\n",
      "Epoch 363/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7883 - acc: 0.8333 - val_loss: 1.2947 - val_acc: 0.5294\n",
      "Epoch 364/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 63us/step - loss: 0.7759 - acc: 0.8125 - val_loss: 1.3041 - val_acc: 0.5294\n",
      "Epoch 365/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7725 - acc: 0.8125 - val_loss: 1.2858 - val_acc: 0.5294\n",
      "Epoch 366/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7867 - acc: 0.7917 - val_loss: 1.2745 - val_acc: 0.5294\n",
      "Epoch 367/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7736 - acc: 0.8750 - val_loss: 1.2929 - val_acc: 0.5294\n",
      "Epoch 368/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7703 - acc: 0.8125 - val_loss: 1.3179 - val_acc: 0.5294\n",
      "Epoch 369/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7751 - acc: 0.8125 - val_loss: 1.2920 - val_acc: 0.5294\n",
      "Epoch 370/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7663 - acc: 0.8125 - val_loss: 1.2578 - val_acc: 0.5882\n",
      "Epoch 371/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7734 - acc: 0.8542 - val_loss: 1.2674 - val_acc: 0.5882\n",
      "Epoch 372/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7653 - acc: 0.8542 - val_loss: 1.3173 - val_acc: 0.5294\n",
      "Epoch 373/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7658 - acc: 0.8333 - val_loss: 1.3288 - val_acc: 0.5294\n",
      "Epoch 374/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7675 - acc: 0.8125 - val_loss: 1.3108 - val_acc: 0.5294\n",
      "Epoch 375/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7598 - acc: 0.8125 - val_loss: 1.2830 - val_acc: 0.5294\n",
      "Epoch 376/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7675 - acc: 0.8542 - val_loss: 1.2814 - val_acc: 0.5294\n",
      "Epoch 377/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7616 - acc: 0.8333 - val_loss: 1.3016 - val_acc: 0.5294\n",
      "Epoch 378/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7581 - acc: 0.8125 - val_loss: 1.3021 - val_acc: 0.5294\n",
      "Epoch 379/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7679 - acc: 0.8125 - val_loss: 1.3037 - val_acc: 0.5294\n",
      "Epoch 380/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7545 - acc: 0.8333 - val_loss: 1.2876 - val_acc: 0.5294\n",
      "Epoch 381/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7650 - acc: 0.8125 - val_loss: 1.2719 - val_acc: 0.5882\n",
      "Epoch 382/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7576 - acc: 0.7917 - val_loss: 1.2863 - val_acc: 0.5294\n",
      "Epoch 383/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7559 - acc: 0.8125 - val_loss: 1.3007 - val_acc: 0.5294\n",
      "Epoch 384/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7588 - acc: 0.8125 - val_loss: 1.3066 - val_acc: 0.5294\n",
      "Epoch 385/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7613 - acc: 0.8125 - val_loss: 1.2753 - val_acc: 0.5882\n",
      "Epoch 386/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7543 - acc: 0.8333 - val_loss: 1.2852 - val_acc: 0.5294\n",
      "Epoch 387/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7508 - acc: 0.8333 - val_loss: 1.3073 - val_acc: 0.5294\n",
      "Epoch 388/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7522 - acc: 0.8125 - val_loss: 1.3075 - val_acc: 0.5294\n",
      "Epoch 389/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7526 - acc: 0.8125 - val_loss: 1.2936 - val_acc: 0.5294\n",
      "Epoch 390/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7480 - acc: 0.8542 - val_loss: 1.2762 - val_acc: 0.5882\n",
      "Epoch 391/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7674 - acc: 0.8125 - val_loss: 1.2803 - val_acc: 0.5882\n",
      "Epoch 392/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7522 - acc: 0.8333 - val_loss: 1.3092 - val_acc: 0.5294\n",
      "Epoch 393/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7492 - acc: 0.8333 - val_loss: 1.3159 - val_acc: 0.4706\n",
      "Epoch 394/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7487 - acc: 0.8333 - val_loss: 1.3184 - val_acc: 0.4706\n",
      "Epoch 395/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 0.7476 - acc: 0.8333 - val_loss: 1.2833 - val_acc: 0.5882\n",
      "Epoch 396/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7481 - acc: 0.7917 - val_loss: 1.2799 - val_acc: 0.5882\n",
      "Epoch 397/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7490 - acc: 0.8125 - val_loss: 1.2911 - val_acc: 0.5882\n",
      "Epoch 398/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7417 - acc: 0.7917 - val_loss: 1.3222 - val_acc: 0.5294\n",
      "Epoch 399/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7453 - acc: 0.8333 - val_loss: 1.3402 - val_acc: 0.4706\n",
      "Epoch 400/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7458 - acc: 0.7917 - val_loss: 1.3358 - val_acc: 0.5294\n",
      "Epoch 401/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7521 - acc: 0.8125 - val_loss: 1.2907 - val_acc: 0.5882\n",
      "Epoch 402/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7408 - acc: 0.8125 - val_loss: 1.2928 - val_acc: 0.5882\n",
      "Epoch 403/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7446 - acc: 0.8125 - val_loss: 1.3122 - val_acc: 0.5294\n",
      "Epoch 404/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7392 - acc: 0.8333 - val_loss: 1.3000 - val_acc: 0.5294\n",
      "Epoch 405/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7388 - acc: 0.8333 - val_loss: 1.3065 - val_acc: 0.5294\n",
      "Epoch 406/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7461 - acc: 0.8125 - val_loss: 1.2997 - val_acc: 0.5882\n",
      "Epoch 407/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7412 - acc: 0.8125 - val_loss: 1.2919 - val_acc: 0.5294\n",
      "Epoch 408/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7379 - acc: 0.8750 - val_loss: 1.3234 - val_acc: 0.4706\n",
      "Epoch 409/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7452 - acc: 0.8125 - val_loss: 1.3324 - val_acc: 0.4706\n",
      "Epoch 410/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7321 - acc: 0.8125 - val_loss: 1.2893 - val_acc: 0.5882\n",
      "Epoch 411/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7455 - acc: 0.8125 - val_loss: 1.2753 - val_acc: 0.6471\n",
      "Epoch 412/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7402 - acc: 0.8542 - val_loss: 1.3064 - val_acc: 0.5294\n",
      "Epoch 413/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7285 - acc: 0.8125 - val_loss: 1.3378 - val_acc: 0.5294\n",
      "Epoch 414/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7563 - acc: 0.8125 - val_loss: 1.3414 - val_acc: 0.5294\n",
      "Epoch 415/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7357 - acc: 0.8125 - val_loss: 1.2834 - val_acc: 0.5882\n",
      "Epoch 416/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7577 - acc: 0.8542 - val_loss: 1.2851 - val_acc: 0.6471\n",
      "Epoch 417/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7309 - acc: 0.8333 - val_loss: 1.3391 - val_acc: 0.4706\n",
      "Epoch 418/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7408 - acc: 0.8125 - val_loss: 1.3724 - val_acc: 0.4706\n",
      "Epoch 419/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7511 - acc: 0.8125 - val_loss: 1.2858 - val_acc: 0.5882\n",
      "Epoch 420/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7289 - acc: 0.8333 - val_loss: 1.2798 - val_acc: 0.5882\n",
      "Epoch 421/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7418 - acc: 0.8333 - val_loss: 1.3020 - val_acc: 0.5294\n",
      "Epoch 422/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7276 - acc: 0.8125 - val_loss: 1.3367 - val_acc: 0.4706\n",
      "Epoch 423/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7292 - acc: 0.8333 - val_loss: 1.3271 - val_acc: 0.4706\n",
      "Epoch 424/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7216 - acc: 0.8542 - val_loss: 1.2974 - val_acc: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7281 - acc: 0.8750 - val_loss: 1.2868 - val_acc: 0.5882\n",
      "Epoch 426/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7321 - acc: 0.8125 - val_loss: 1.3137 - val_acc: 0.5882\n",
      "Epoch 427/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7238 - acc: 0.8333 - val_loss: 1.3303 - val_acc: 0.4706\n",
      "Epoch 428/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7210 - acc: 0.8333 - val_loss: 1.3420 - val_acc: 0.4706\n",
      "Epoch 429/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7322 - acc: 0.8333 - val_loss: 1.3203 - val_acc: 0.5294\n",
      "Epoch 430/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7166 - acc: 0.8125 - val_loss: 1.3149 - val_acc: 0.5882\n",
      "Epoch 431/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7227 - acc: 0.8125 - val_loss: 1.3075 - val_acc: 0.5882\n",
      "Epoch 432/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7186 - acc: 0.8333 - val_loss: 1.2967 - val_acc: 0.5882\n",
      "Epoch 433/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7227 - acc: 0.8542 - val_loss: 1.2993 - val_acc: 0.5882\n",
      "Epoch 434/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7167 - acc: 0.8333 - val_loss: 1.3388 - val_acc: 0.5294\n",
      "Epoch 435/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7209 - acc: 0.8125 - val_loss: 1.3353 - val_acc: 0.5294\n",
      "Epoch 436/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7190 - acc: 0.8125 - val_loss: 1.3223 - val_acc: 0.5294\n",
      "Epoch 437/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7136 - acc: 0.8125 - val_loss: 1.3055 - val_acc: 0.5882\n",
      "Epoch 438/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7167 - acc: 0.8333 - val_loss: 1.3058 - val_acc: 0.5882\n",
      "Epoch 439/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7234 - acc: 0.8125 - val_loss: 1.3334 - val_acc: 0.4706\n",
      "Epoch 440/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7287 - acc: 0.8333 - val_loss: 1.3301 - val_acc: 0.4706\n",
      "Epoch 441/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7189 - acc: 0.8542 - val_loss: 1.3010 - val_acc: 0.5882\n",
      "Epoch 442/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7107 - acc: 0.8333 - val_loss: 1.3142 - val_acc: 0.5882\n",
      "Epoch 443/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7184 - acc: 0.8125 - val_loss: 1.3211 - val_acc: 0.5882\n",
      "Epoch 444/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7269 - acc: 0.8125 - val_loss: 1.3470 - val_acc: 0.4706\n",
      "Epoch 445/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7135 - acc: 0.8333 - val_loss: 1.3194 - val_acc: 0.5882\n",
      "Epoch 446/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7178 - acc: 0.8750 - val_loss: 1.3162 - val_acc: 0.5294\n",
      "Epoch 447/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7045 - acc: 0.8542 - val_loss: 1.3286 - val_acc: 0.5882\n",
      "Epoch 448/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7176 - acc: 0.8125 - val_loss: 1.3184 - val_acc: 0.5882\n",
      "Epoch 449/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7136 - acc: 0.8125 - val_loss: 1.3258 - val_acc: 0.5294\n",
      "Epoch 450/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7062 - acc: 0.8125 - val_loss: 1.3262 - val_acc: 0.5294\n",
      "Epoch 451/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7129 - acc: 0.8542 - val_loss: 1.3351 - val_acc: 0.4706\n",
      "Epoch 452/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7096 - acc: 0.8333 - val_loss: 1.3321 - val_acc: 0.5882\n",
      "Epoch 453/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7038 - acc: 0.8333 - val_loss: 1.3110 - val_acc: 0.5882\n",
      "Epoch 454/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7086 - acc: 0.7917 - val_loss: 1.3199 - val_acc: 0.5882\n",
      "Epoch 455/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7030 - acc: 0.8542 - val_loss: 1.3199 - val_acc: 0.5882\n",
      "Epoch 456/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7134 - acc: 0.8333 - val_loss: 1.3257 - val_acc: 0.5882\n",
      "Epoch 457/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7029 - acc: 0.8333 - val_loss: 1.3727 - val_acc: 0.4706\n",
      "Epoch 458/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7124 - acc: 0.8333 - val_loss: 1.3439 - val_acc: 0.4706\n",
      "Epoch 459/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7089 - acc: 0.8542 - val_loss: 1.3041 - val_acc: 0.5882\n",
      "Epoch 460/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7026 - acc: 0.8542 - val_loss: 1.3037 - val_acc: 0.5882\n",
      "Epoch 461/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6991 - acc: 0.8542 - val_loss: 1.3230 - val_acc: 0.5294\n",
      "Epoch 462/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6995 - acc: 0.8125 - val_loss: 1.3404 - val_acc: 0.4706\n",
      "Epoch 463/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6993 - acc: 0.8333 - val_loss: 1.3292 - val_acc: 0.5294\n",
      "Epoch 464/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6971 - acc: 0.8333 - val_loss: 1.3374 - val_acc: 0.4706\n",
      "Epoch 465/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6994 - acc: 0.8333 - val_loss: 1.3294 - val_acc: 0.5882\n",
      "Epoch 466/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6963 - acc: 0.8333 - val_loss: 1.3191 - val_acc: 0.5882\n",
      "Epoch 467/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6965 - acc: 0.8333 - val_loss: 1.3242 - val_acc: 0.5882\n",
      "Epoch 468/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6961 - acc: 0.8333 - val_loss: 1.3440 - val_acc: 0.4706\n",
      "Epoch 469/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6948 - acc: 0.8542 - val_loss: 1.3536 - val_acc: 0.4706\n",
      "Epoch 470/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6962 - acc: 0.8333 - val_loss: 1.3350 - val_acc: 0.5294\n",
      "Epoch 471/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6936 - acc: 0.8125 - val_loss: 1.3140 - val_acc: 0.5882\n",
      "Epoch 472/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6984 - acc: 0.8542 - val_loss: 1.3201 - val_acc: 0.5882\n",
      "Epoch 473/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6957 - acc: 0.8333 - val_loss: 1.3480 - val_acc: 0.5294\n",
      "Epoch 474/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.6985 - acc: 0.8125 - val_loss: 1.3627 - val_acc: 0.4706\n",
      "Epoch 475/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6973 - acc: 0.8542 - val_loss: 1.3429 - val_acc: 0.5294\n",
      "Epoch 476/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6939 - acc: 0.8750 - val_loss: 1.3514 - val_acc: 0.4706\n",
      "Epoch 477/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6941 - acc: 0.8333 - val_loss: 1.3458 - val_acc: 0.5882\n",
      "Epoch 478/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6882 - acc: 0.8542 - val_loss: 1.3190 - val_acc: 0.5882\n",
      "Epoch 479/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6924 - acc: 0.8750 - val_loss: 1.3215 - val_acc: 0.5882\n",
      "Epoch 480/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.6979 - acc: 0.8542 - val_loss: 1.3531 - val_acc: 0.4706\n",
      "Epoch 481/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6902 - acc: 0.8333 - val_loss: 1.3596 - val_acc: 0.4706\n",
      "Epoch 482/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6866 - acc: 0.8333 - val_loss: 1.3357 - val_acc: 0.5294\n",
      "Epoch 483/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6967 - acc: 0.8750 - val_loss: 1.3138 - val_acc: 0.6471\n",
      "Epoch 484/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6905 - acc: 0.8542 - val_loss: 1.3278 - val_acc: 0.5882\n",
      "Epoch 485/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 83us/step - loss: 0.7060 - acc: 0.8125 - val_loss: 1.3926 - val_acc: 0.4706\n",
      "Epoch 486/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6923 - acc: 0.8333 - val_loss: 1.3436 - val_acc: 0.4706\n",
      "Epoch 487/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7096 - acc: 0.8750 - val_loss: 1.3282 - val_acc: 0.6471\n",
      "Epoch 488/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6955 - acc: 0.8750 - val_loss: 1.3523 - val_acc: 0.4706\n",
      "Epoch 489/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6811 - acc: 0.8333 - val_loss: 1.3961 - val_acc: 0.4706\n",
      "Epoch 490/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7123 - acc: 0.8125 - val_loss: 1.3746 - val_acc: 0.4706\n",
      "Epoch 491/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6856 - acc: 0.8125 - val_loss: 1.3251 - val_acc: 0.6471\n",
      "Epoch 492/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.7157 - acc: 0.8542 - val_loss: 1.3385 - val_acc: 0.6471\n",
      "Epoch 493/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6984 - acc: 0.8333 - val_loss: 1.3995 - val_acc: 0.4706\n",
      "Epoch 494/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7033 - acc: 0.8125 - val_loss: 1.4123 - val_acc: 0.5294\n",
      "Epoch 495/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7007 - acc: 0.8125 - val_loss: 1.3308 - val_acc: 0.5882\n",
      "Epoch 496/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7191 - acc: 0.8333 - val_loss: 1.3157 - val_acc: 0.6471\n",
      "Epoch 497/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6942 - acc: 0.8750 - val_loss: 1.3653 - val_acc: 0.4706\n",
      "Epoch 498/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6930 - acc: 0.8333 - val_loss: 1.4365 - val_acc: 0.4706\n",
      "Epoch 499/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.7152 - acc: 0.8125 - val_loss: 1.3648 - val_acc: 0.5882\n",
      "Epoch 500/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6797 - acc: 0.8333 - val_loss: 1.3320 - val_acc: 0.6471\n",
      "Epoch 501/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6918 - acc: 0.8542 - val_loss: 1.3294 - val_acc: 0.6471\n",
      "Epoch 502/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6762 - acc: 0.8750 - val_loss: 1.3681 - val_acc: 0.4706\n",
      "Epoch 503/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6856 - acc: 0.8333 - val_loss: 1.4147 - val_acc: 0.4706\n",
      "Epoch 504/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6849 - acc: 0.8333 - val_loss: 1.3526 - val_acc: 0.5294\n",
      "Epoch 505/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6978 - acc: 0.8542 - val_loss: 1.3386 - val_acc: 0.6471\n",
      "Epoch 506/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6753 - acc: 0.8542 - val_loss: 1.3711 - val_acc: 0.4706\n",
      "Epoch 507/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6720 - acc: 0.8333 - val_loss: 1.3889 - val_acc: 0.4706\n",
      "Epoch 508/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6827 - acc: 0.8125 - val_loss: 1.3767 - val_acc: 0.4706\n",
      "Epoch 509/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6863 - acc: 0.8333 - val_loss: 1.3663 - val_acc: 0.5882\n",
      "Epoch 510/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6807 - acc: 0.8750 - val_loss: 1.3599 - val_acc: 0.4706\n",
      "Epoch 511/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6771 - acc: 0.8333 - val_loss: 1.3438 - val_acc: 0.5882\n",
      "Epoch 512/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6744 - acc: 0.8333 - val_loss: 1.3422 - val_acc: 0.5882\n",
      "Epoch 513/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6726 - acc: 0.8542 - val_loss: 1.3463 - val_acc: 0.6471\n",
      "Epoch 514/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6754 - acc: 0.8750 - val_loss: 1.3448 - val_acc: 0.6471\n",
      "Epoch 515/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6742 - acc: 0.8750 - val_loss: 1.3794 - val_acc: 0.4706\n",
      "Epoch 516/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6864 - acc: 0.8125 - val_loss: 1.3697 - val_acc: 0.5882\n",
      "Epoch 517/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6651 - acc: 0.8542 - val_loss: 1.3586 - val_acc: 0.5882\n",
      "Epoch 518/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6772 - acc: 0.8750 - val_loss: 1.3587 - val_acc: 0.5882\n",
      "Epoch 519/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6693 - acc: 0.8750 - val_loss: 1.3652 - val_acc: 0.5882\n",
      "Epoch 520/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6736 - acc: 0.8542 - val_loss: 1.3741 - val_acc: 0.5294\n",
      "Epoch 521/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6669 - acc: 0.8333 - val_loss: 1.3598 - val_acc: 0.5882\n",
      "Epoch 522/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6617 - acc: 0.8750 - val_loss: 1.3675 - val_acc: 0.5882\n",
      "Epoch 523/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6672 - acc: 0.8750 - val_loss: 1.3695 - val_acc: 0.5882\n",
      "Epoch 524/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6730 - acc: 0.8542 - val_loss: 1.3758 - val_acc: 0.5882\n",
      "Epoch 525/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6671 - acc: 0.8333 - val_loss: 1.3735 - val_acc: 0.4706\n",
      "Epoch 526/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6620 - acc: 0.8542 - val_loss: 1.3586 - val_acc: 0.5294\n",
      "Epoch 527/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6740 - acc: 0.8333 - val_loss: 1.3466 - val_acc: 0.5882\n",
      "Epoch 528/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 0.6618 - acc: 0.8750 - val_loss: 1.3600 - val_acc: 0.6471\n",
      "Epoch 529/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6607 - acc: 0.8750 - val_loss: 1.3918 - val_acc: 0.4706\n",
      "Epoch 530/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6745 - acc: 0.8333 - val_loss: 1.3802 - val_acc: 0.4706\n",
      "Epoch 531/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6777 - acc: 0.8333 - val_loss: 1.3426 - val_acc: 0.6471\n",
      "Epoch 532/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6702 - acc: 0.8542 - val_loss: 1.3363 - val_acc: 0.5882\n",
      "Epoch 533/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6582 - acc: 0.8542 - val_loss: 1.3808 - val_acc: 0.5294\n",
      "Epoch 534/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6601 - acc: 0.8333 - val_loss: 1.4061 - val_acc: 0.4706\n",
      "Epoch 535/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6667 - acc: 0.8333 - val_loss: 1.3859 - val_acc: 0.4706\n",
      "Epoch 536/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6591 - acc: 0.8750 - val_loss: 1.3707 - val_acc: 0.4706\n",
      "Epoch 537/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6613 - acc: 0.8333 - val_loss: 1.3699 - val_acc: 0.5294\n",
      "Epoch 538/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6556 - acc: 0.8750 - val_loss: 1.3433 - val_acc: 0.5882\n",
      "Epoch 539/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6567 - acc: 0.8750 - val_loss: 1.3517 - val_acc: 0.5882\n",
      "Epoch 540/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6623 - acc: 0.8750 - val_loss: 1.3671 - val_acc: 0.5882\n",
      "Epoch 541/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6560 - acc: 0.8542 - val_loss: 1.4006 - val_acc: 0.4706\n",
      "Epoch 542/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.6630 - acc: 0.8542 - val_loss: 1.3774 - val_acc: 0.5294\n",
      "Epoch 543/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6596 - acc: 0.8542 - val_loss: 1.3738 - val_acc: 0.5294\n",
      "Epoch 544/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6644 - acc: 0.8542 - val_loss: 1.3593 - val_acc: 0.5882\n",
      "Epoch 545/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6548 - acc: 0.8542 - val_loss: 1.3526 - val_acc: 0.6471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6533 - acc: 0.8750 - val_loss: 1.3844 - val_acc: 0.5294\n",
      "Epoch 547/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6599 - acc: 0.8750 - val_loss: 1.3970 - val_acc: 0.4706\n",
      "Epoch 548/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6642 - acc: 0.8333 - val_loss: 1.3936 - val_acc: 0.5294\n",
      "Epoch 549/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6544 - acc: 0.8333 - val_loss: 1.3566 - val_acc: 0.5882\n",
      "Epoch 550/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6572 - acc: 0.8542 - val_loss: 1.3505 - val_acc: 0.6471\n",
      "Epoch 551/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6558 - acc: 0.8750 - val_loss: 1.3711 - val_acc: 0.5882\n",
      "Epoch 552/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6508 - acc: 0.8333 - val_loss: 1.4055 - val_acc: 0.4706\n",
      "Epoch 553/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6599 - acc: 0.8333 - val_loss: 1.3721 - val_acc: 0.5882\n",
      "Epoch 554/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6505 - acc: 0.8750 - val_loss: 1.3712 - val_acc: 0.5882\n",
      "Epoch 555/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6471 - acc: 0.8542 - val_loss: 1.3826 - val_acc: 0.5882\n",
      "Epoch 556/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6458 - acc: 0.8542 - val_loss: 1.3964 - val_acc: 0.5294\n",
      "Epoch 557/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6443 - acc: 0.8750 - val_loss: 1.3962 - val_acc: 0.4706\n",
      "Epoch 558/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6451 - acc: 0.8750 - val_loss: 1.3748 - val_acc: 0.4706\n",
      "Epoch 559/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6459 - acc: 0.8750 - val_loss: 1.3549 - val_acc: 0.6471\n",
      "Epoch 560/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6448 - acc: 0.8750 - val_loss: 1.3691 - val_acc: 0.5882\n",
      "Epoch 561/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6483 - acc: 0.8333 - val_loss: 1.3856 - val_acc: 0.5882\n",
      "Epoch 562/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6584 - acc: 0.8333 - val_loss: 1.4150 - val_acc: 0.4706\n",
      "Epoch 563/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6558 - acc: 0.8542 - val_loss: 1.3862 - val_acc: 0.6471\n",
      "Epoch 564/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6532 - acc: 0.8750 - val_loss: 1.3819 - val_acc: 0.5882\n",
      "Epoch 565/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6427 - acc: 0.8542 - val_loss: 1.4101 - val_acc: 0.5882\n",
      "Epoch 566/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6470 - acc: 0.8333 - val_loss: 1.4184 - val_acc: 0.4706\n",
      "Epoch 567/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6511 - acc: 0.8333 - val_loss: 1.4022 - val_acc: 0.4706\n",
      "Epoch 568/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6490 - acc: 0.8750 - val_loss: 1.3594 - val_acc: 0.6471\n",
      "Epoch 569/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6512 - acc: 0.8542 - val_loss: 1.3634 - val_acc: 0.5882\n",
      "Epoch 570/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6440 - acc: 0.8542 - val_loss: 1.4138 - val_acc: 0.4706\n",
      "Epoch 571/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6486 - acc: 0.8333 - val_loss: 1.3992 - val_acc: 0.4706\n",
      "Epoch 572/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6410 - acc: 0.8750 - val_loss: 1.3848 - val_acc: 0.6471\n",
      "Epoch 573/1000\n",
      "48/48 [==============================] - 0s 84us/step - loss: 0.6391 - acc: 0.8750 - val_loss: 1.3848 - val_acc: 0.5882\n",
      "Epoch 574/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6362 - acc: 0.8750 - val_loss: 1.3894 - val_acc: 0.5882\n",
      "Epoch 575/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6367 - acc: 0.8750 - val_loss: 1.3706 - val_acc: 0.5882\n",
      "Epoch 576/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6381 - acc: 0.8750 - val_loss: 1.3724 - val_acc: 0.5882\n",
      "Epoch 577/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6345 - acc: 0.8750 - val_loss: 1.3919 - val_acc: 0.5294\n",
      "Epoch 578/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6436 - acc: 0.8333 - val_loss: 1.4037 - val_acc: 0.4706\n",
      "Epoch 579/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6325 - acc: 0.8750 - val_loss: 1.3801 - val_acc: 0.5882\n",
      "Epoch 580/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6375 - acc: 0.8750 - val_loss: 1.3813 - val_acc: 0.6471\n",
      "Epoch 581/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6379 - acc: 0.8750 - val_loss: 1.3898 - val_acc: 0.5882\n",
      "Epoch 582/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6435 - acc: 0.8542 - val_loss: 1.4013 - val_acc: 0.5882\n",
      "Epoch 583/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6535 - acc: 0.8333 - val_loss: 1.4125 - val_acc: 0.5294\n",
      "Epoch 584/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6417 - acc: 0.8750 - val_loss: 1.3731 - val_acc: 0.6471\n",
      "Epoch 585/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6387 - acc: 0.8750 - val_loss: 1.3793 - val_acc: 0.5882\n",
      "Epoch 586/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6343 - acc: 0.8333 - val_loss: 1.3813 - val_acc: 0.5882\n",
      "Epoch 587/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6371 - acc: 0.8333 - val_loss: 1.3634 - val_acc: 0.5882\n",
      "Epoch 588/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6300 - acc: 0.8750 - val_loss: 1.3762 - val_acc: 0.6471\n",
      "Epoch 589/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6476 - acc: 0.8750 - val_loss: 1.4040 - val_acc: 0.5294\n",
      "Epoch 590/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6402 - acc: 0.8542 - val_loss: 1.4192 - val_acc: 0.5294\n",
      "Epoch 591/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6363 - acc: 0.8542 - val_loss: 1.3898 - val_acc: 0.5882\n",
      "Epoch 592/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6410 - acc: 0.8542 - val_loss: 1.3903 - val_acc: 0.6471\n",
      "Epoch 593/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6380 - acc: 0.8750 - val_loss: 1.4167 - val_acc: 0.5294\n",
      "Epoch 594/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6317 - acc: 0.8750 - val_loss: 1.4256 - val_acc: 0.4706\n",
      "Epoch 595/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6355 - acc: 0.8542 - val_loss: 1.4057 - val_acc: 0.5882\n",
      "Epoch 596/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6307 - acc: 0.8542 - val_loss: 1.3778 - val_acc: 0.5882\n",
      "Epoch 597/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6281 - acc: 0.8750 - val_loss: 1.3959 - val_acc: 0.6471\n",
      "Epoch 598/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6344 - acc: 0.8750 - val_loss: 1.4036 - val_acc: 0.6471\n",
      "Epoch 599/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.6230 - acc: 0.8750 - val_loss: 1.4183 - val_acc: 0.5882\n",
      "Epoch 600/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6273 - acc: 0.8542 - val_loss: 1.4172 - val_acc: 0.5882\n",
      "Epoch 601/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6390 - acc: 0.8333 - val_loss: 1.3993 - val_acc: 0.5882\n",
      "Epoch 602/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6246 - acc: 0.8750 - val_loss: 1.3713 - val_acc: 0.6471\n",
      "Epoch 603/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6405 - acc: 0.8542 - val_loss: 1.3863 - val_acc: 0.6471\n",
      "Epoch 604/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6220 - acc: 0.8750 - val_loss: 1.4523 - val_acc: 0.4706\n",
      "Epoch 605/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6527 - acc: 0.8333 - val_loss: 1.4760 - val_acc: 0.4706\n",
      "Epoch 606/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6352 - acc: 0.8333 - val_loss: 1.4004 - val_acc: 0.6471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6429 - acc: 0.8542 - val_loss: 1.3799 - val_acc: 0.6471\n",
      "Epoch 608/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6326 - acc: 0.8750 - val_loss: 1.3941 - val_acc: 0.5882\n",
      "Epoch 609/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6217 - acc: 0.8333 - val_loss: 1.4746 - val_acc: 0.4706\n",
      "Epoch 610/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6492 - acc: 0.8125 - val_loss: 1.4545 - val_acc: 0.4706\n",
      "Epoch 611/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6299 - acc: 0.8542 - val_loss: 1.3948 - val_acc: 0.6471\n",
      "Epoch 612/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6320 - acc: 0.8750 - val_loss: 1.3863 - val_acc: 0.6471\n",
      "Epoch 613/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6320 - acc: 0.8542 - val_loss: 1.3849 - val_acc: 0.5882\n",
      "Epoch 614/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6258 - acc: 0.8333 - val_loss: 1.4287 - val_acc: 0.4706\n",
      "Epoch 615/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6227 - acc: 0.8542 - val_loss: 1.4226 - val_acc: 0.5294\n",
      "Epoch 616/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6197 - acc: 0.8750 - val_loss: 1.4002 - val_acc: 0.6471\n",
      "Epoch 617/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6215 - acc: 0.8750 - val_loss: 1.3874 - val_acc: 0.6471\n",
      "Epoch 618/1000\n",
      "48/48 [==============================] - 0s 62us/step - loss: 0.6215 - acc: 0.8542 - val_loss: 1.3933 - val_acc: 0.5882\n",
      "Epoch 619/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6318 - acc: 0.8750 - val_loss: 1.4406 - val_acc: 0.4706\n",
      "Epoch 620/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6192 - acc: 0.8750 - val_loss: 1.4156 - val_acc: 0.6471\n",
      "Epoch 621/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6130 - acc: 0.8750 - val_loss: 1.3939 - val_acc: 0.6471\n",
      "Epoch 622/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6199 - acc: 0.8750 - val_loss: 1.4026 - val_acc: 0.5882\n",
      "Epoch 623/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6206 - acc: 0.8542 - val_loss: 1.4243 - val_acc: 0.5882\n",
      "Epoch 624/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6136 - acc: 0.8750 - val_loss: 1.4309 - val_acc: 0.5882\n",
      "Epoch 625/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6189 - acc: 0.8750 - val_loss: 1.4257 - val_acc: 0.5882\n",
      "Epoch 626/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6202 - acc: 0.8750 - val_loss: 1.3984 - val_acc: 0.6471\n",
      "Epoch 627/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6143 - acc: 0.8750 - val_loss: 1.4180 - val_acc: 0.5882\n",
      "Epoch 628/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6269 - acc: 0.8542 - val_loss: 1.4273 - val_acc: 0.5882\n",
      "Epoch 629/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6182 - acc: 0.8542 - val_loss: 1.4175 - val_acc: 0.6471\n",
      "Epoch 630/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6166 - acc: 0.8750 - val_loss: 1.4030 - val_acc: 0.6471\n",
      "Epoch 631/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6187 - acc: 0.8750 - val_loss: 1.4005 - val_acc: 0.5882\n",
      "Epoch 632/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6229 - acc: 0.8750 - val_loss: 1.4416 - val_acc: 0.5882\n",
      "Epoch 633/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6285 - acc: 0.8333 - val_loss: 1.4017 - val_acc: 0.5882\n",
      "Epoch 634/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6147 - acc: 0.8750 - val_loss: 1.4008 - val_acc: 0.6471\n",
      "Epoch 635/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6269 - acc: 0.8750 - val_loss: 1.4350 - val_acc: 0.5882\n",
      "Epoch 636/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6219 - acc: 0.8958 - val_loss: 1.4496 - val_acc: 0.4706\n",
      "Epoch 637/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6267 - acc: 0.8333 - val_loss: 1.4411 - val_acc: 0.5882\n",
      "Epoch 638/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6178 - acc: 0.8542 - val_loss: 1.3917 - val_acc: 0.5882\n",
      "Epoch 639/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6244 - acc: 0.8750 - val_loss: 1.3955 - val_acc: 0.6471\n",
      "Epoch 640/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6555 - acc: 0.8750 - val_loss: 1.4428 - val_acc: 0.5882\n",
      "Epoch 641/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6197 - acc: 0.8958 - val_loss: 1.4604 - val_acc: 0.5294\n",
      "Epoch 642/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6126 - acc: 0.8542 - val_loss: 1.4156 - val_acc: 0.5882\n",
      "Epoch 643/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6234 - acc: 0.8542 - val_loss: 1.3939 - val_acc: 0.5882\n",
      "Epoch 644/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6187 - acc: 0.8542 - val_loss: 1.4230 - val_acc: 0.6471\n",
      "Epoch 645/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6186 - acc: 0.8750 - val_loss: 1.4531 - val_acc: 0.5882\n",
      "Epoch 646/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6176 - acc: 0.8542 - val_loss: 1.4722 - val_acc: 0.5294\n",
      "Epoch 647/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6204 - acc: 0.8542 - val_loss: 1.4264 - val_acc: 0.5882\n",
      "Epoch 648/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6105 - acc: 0.8750 - val_loss: 1.4240 - val_acc: 0.6471\n",
      "Epoch 649/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6056 - acc: 0.8750 - val_loss: 1.4403 - val_acc: 0.5882\n",
      "Epoch 650/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6036 - acc: 0.8750 - val_loss: 1.4438 - val_acc: 0.5882\n",
      "Epoch 651/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6077 - acc: 0.8750 - val_loss: 1.4317 - val_acc: 0.5882\n",
      "Epoch 652/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6035 - acc: 0.8750 - val_loss: 1.4466 - val_acc: 0.4706\n",
      "Epoch 653/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6021 - acc: 0.8958 - val_loss: 1.4279 - val_acc: 0.5882\n",
      "Epoch 654/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6012 - acc: 0.8750 - val_loss: 1.4134 - val_acc: 0.6471\n",
      "Epoch 655/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5988 - acc: 0.8750 - val_loss: 1.4257 - val_acc: 0.5882\n",
      "Epoch 656/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6009 - acc: 0.8750 - val_loss: 1.4280 - val_acc: 0.5882\n",
      "Epoch 657/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6004 - acc: 0.8750 - val_loss: 1.4368 - val_acc: 0.6471\n",
      "Epoch 658/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6049 - acc: 0.8750 - val_loss: 1.4420 - val_acc: 0.5882\n",
      "Epoch 659/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5993 - acc: 0.8750 - val_loss: 1.4168 - val_acc: 0.5882\n",
      "Epoch 660/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6011 - acc: 0.8750 - val_loss: 1.4253 - val_acc: 0.5882\n",
      "Epoch 661/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6107 - acc: 0.8542 - val_loss: 1.4541 - val_acc: 0.5294\n",
      "Epoch 662/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6104 - acc: 0.8542 - val_loss: 1.4422 - val_acc: 0.5882\n",
      "Epoch 663/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6036 - acc: 0.8750 - val_loss: 1.4357 - val_acc: 0.6471\n",
      "Epoch 664/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6056 - acc: 0.8750 - val_loss: 1.4526 - val_acc: 0.5294\n",
      "Epoch 665/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5964 - acc: 0.8750 - val_loss: 1.4381 - val_acc: 0.6471\n",
      "Epoch 666/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6031 - acc: 0.8750 - val_loss: 1.4428 - val_acc: 0.5882\n",
      "Epoch 667/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6096 - acc: 0.8750 - val_loss: 1.4255 - val_acc: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6030 - acc: 0.8750 - val_loss: 1.4414 - val_acc: 0.5882\n",
      "Epoch 669/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6044 - acc: 0.8542 - val_loss: 1.4805 - val_acc: 0.4706\n",
      "Epoch 670/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6081 - acc: 0.8958 - val_loss: 1.4363 - val_acc: 0.6471\n",
      "Epoch 671/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6108 - acc: 0.8750 - val_loss: 1.4331 - val_acc: 0.5882\n",
      "Epoch 672/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5947 - acc: 0.8750 - val_loss: 1.4213 - val_acc: 0.5882\n",
      "Epoch 673/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5955 - acc: 0.8750 - val_loss: 1.4363 - val_acc: 0.5882\n",
      "Epoch 674/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5974 - acc: 0.8750 - val_loss: 1.4683 - val_acc: 0.5882\n",
      "Epoch 675/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5990 - acc: 0.8958 - val_loss: 1.4759 - val_acc: 0.5294\n",
      "Epoch 676/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5960 - acc: 0.8750 - val_loss: 1.4587 - val_acc: 0.5882\n",
      "Epoch 677/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5945 - acc: 0.8750 - val_loss: 1.4304 - val_acc: 0.6471\n",
      "Epoch 678/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6005 - acc: 0.8750 - val_loss: 1.4209 - val_acc: 0.5882\n",
      "Epoch 679/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5929 - acc: 0.8542 - val_loss: 1.4643 - val_acc: 0.5294\n",
      "Epoch 680/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6008 - acc: 0.8750 - val_loss: 1.4514 - val_acc: 0.5294\n",
      "Epoch 681/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5908 - acc: 0.8958 - val_loss: 1.4529 - val_acc: 0.5882\n",
      "Epoch 682/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5975 - acc: 0.8750 - val_loss: 1.4560 - val_acc: 0.5882\n",
      "Epoch 683/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6066 - acc: 0.8750 - val_loss: 1.4387 - val_acc: 0.6471\n",
      "Epoch 684/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.6051 - acc: 0.8542 - val_loss: 1.4818 - val_acc: 0.5294\n",
      "Epoch 685/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5958 - acc: 0.8542 - val_loss: 1.4832 - val_acc: 0.5882\n",
      "Epoch 686/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5971 - acc: 0.8750 - val_loss: 1.4719 - val_acc: 0.5882\n",
      "Epoch 687/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6094 - acc: 0.8958 - val_loss: 1.4471 - val_acc: 0.5882\n",
      "Epoch 688/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5920 - acc: 0.8750 - val_loss: 1.4352 - val_acc: 0.6471\n",
      "Epoch 689/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5924 - acc: 0.8750 - val_loss: 1.4535 - val_acc: 0.5882\n",
      "Epoch 690/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5932 - acc: 0.8750 - val_loss: 1.4810 - val_acc: 0.5294\n",
      "Epoch 691/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5858 - acc: 0.8958 - val_loss: 1.4589 - val_acc: 0.5882\n",
      "Epoch 692/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5867 - acc: 0.8958 - val_loss: 1.4536 - val_acc: 0.6471\n",
      "Epoch 693/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5992 - acc: 0.8750 - val_loss: 1.4634 - val_acc: 0.6471\n",
      "Epoch 694/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5826 - acc: 0.8750 - val_loss: 1.4988 - val_acc: 0.4706\n",
      "Epoch 695/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5922 - acc: 0.8958 - val_loss: 1.4759 - val_acc: 0.4706\n",
      "Epoch 696/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5912 - acc: 0.8958 - val_loss: 1.4270 - val_acc: 0.6471\n",
      "Epoch 697/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5869 - acc: 0.8750 - val_loss: 1.4210 - val_acc: 0.5882\n",
      "Epoch 698/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5970 - acc: 0.8333 - val_loss: 1.4633 - val_acc: 0.5294\n",
      "Epoch 699/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5911 - acc: 0.8958 - val_loss: 1.4981 - val_acc: 0.5882\n",
      "Epoch 700/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.6031 - acc: 0.8750 - val_loss: 1.4618 - val_acc: 0.6471\n",
      "Epoch 701/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5870 - acc: 0.8750 - val_loss: 1.4574 - val_acc: 0.5882\n",
      "Epoch 702/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5855 - acc: 0.8542 - val_loss: 1.4707 - val_acc: 0.5882\n",
      "Epoch 703/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5868 - acc: 0.8542 - val_loss: 1.4712 - val_acc: 0.5882\n",
      "Epoch 704/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5912 - acc: 0.9167 - val_loss: 1.4762 - val_acc: 0.5882\n",
      "Epoch 705/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5868 - acc: 0.8958 - val_loss: 1.4491 - val_acc: 0.6471\n",
      "Epoch 706/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.6139 - acc: 0.8750 - val_loss: 1.4606 - val_acc: 0.5882\n",
      "Epoch 707/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5892 - acc: 0.8333 - val_loss: 1.5290 - val_acc: 0.5294\n",
      "Epoch 708/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5951 - acc: 0.8542 - val_loss: 1.4968 - val_acc: 0.5294\n",
      "Epoch 709/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5863 - acc: 0.8750 - val_loss: 1.4502 - val_acc: 0.6471\n",
      "Epoch 710/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.6000 - acc: 0.8750 - val_loss: 1.4309 - val_acc: 0.6471\n",
      "Epoch 711/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5950 - acc: 0.8750 - val_loss: 1.4690 - val_acc: 0.5294\n",
      "Epoch 712/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.5869 - acc: 0.8750 - val_loss: 1.4606 - val_acc: 0.5882\n",
      "Epoch 713/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5783 - acc: 0.8958 - val_loss: 1.4631 - val_acc: 0.6471\n",
      "Epoch 714/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5805 - acc: 0.8750 - val_loss: 1.4710 - val_acc: 0.5882\n",
      "Epoch 715/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5829 - acc: 0.8750 - val_loss: 1.4798 - val_acc: 0.5294\n",
      "Epoch 716/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5911 - acc: 0.8542 - val_loss: 1.5050 - val_acc: 0.5294\n",
      "Epoch 717/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5793 - acc: 0.8958 - val_loss: 1.4556 - val_acc: 0.6471\n",
      "Epoch 718/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5832 - acc: 0.8750 - val_loss: 1.4259 - val_acc: 0.6471\n",
      "Epoch 719/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5902 - acc: 0.8958 - val_loss: 1.4486 - val_acc: 0.5882\n",
      "Epoch 720/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5835 - acc: 0.8958 - val_loss: 1.4518 - val_acc: 0.5882\n",
      "Epoch 721/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5771 - acc: 0.8750 - val_loss: 1.4564 - val_acc: 0.5882\n",
      "Epoch 722/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5730 - acc: 0.8750 - val_loss: 1.4504 - val_acc: 0.6471\n",
      "Epoch 723/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5752 - acc: 0.8750 - val_loss: 1.4618 - val_acc: 0.6471\n",
      "Epoch 724/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5722 - acc: 0.8958 - val_loss: 1.4876 - val_acc: 0.5294\n",
      "Epoch 725/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5768 - acc: 0.8958 - val_loss: 1.4555 - val_acc: 0.5882\n",
      "Epoch 726/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5708 - acc: 0.8750 - val_loss: 1.4541 - val_acc: 0.6471\n",
      "Epoch 727/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5774 - acc: 0.8750 - val_loss: 1.4630 - val_acc: 0.6471\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 42us/step - loss: 0.5706 - acc: 0.8750 - val_loss: 1.4841 - val_acc: 0.5294\n",
      "Epoch 729/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5839 - acc: 0.8542 - val_loss: 1.4944 - val_acc: 0.5294\n",
      "Epoch 730/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5751 - acc: 0.8958 - val_loss: 1.4908 - val_acc: 0.5882\n",
      "Epoch 731/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5718 - acc: 0.9167 - val_loss: 1.4645 - val_acc: 0.6471\n",
      "Epoch 732/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5841 - acc: 0.9167 - val_loss: 1.4517 - val_acc: 0.6471\n",
      "Epoch 733/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5713 - acc: 0.8958 - val_loss: 1.4692 - val_acc: 0.5882\n",
      "Epoch 734/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.5811 - acc: 0.8750 - val_loss: 1.4593 - val_acc: 0.5882\n",
      "Epoch 735/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5767 - acc: 0.8958 - val_loss: 1.4703 - val_acc: 0.6471\n",
      "Epoch 736/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5706 - acc: 0.8750 - val_loss: 1.4933 - val_acc: 0.5882\n",
      "Epoch 737/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.5779 - acc: 0.9167 - val_loss: 1.4979 - val_acc: 0.5882\n",
      "Epoch 738/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5685 - acc: 0.8750 - val_loss: 1.4631 - val_acc: 0.5882\n",
      "Epoch 739/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5733 - acc: 0.8958 - val_loss: 1.4519 - val_acc: 0.5882\n",
      "Epoch 740/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5772 - acc: 0.8958 - val_loss: 1.4623 - val_acc: 0.5882\n",
      "Epoch 741/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5711 - acc: 0.9167 - val_loss: 1.4767 - val_acc: 0.6471\n",
      "Epoch 742/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5736 - acc: 0.9167 - val_loss: 1.4781 - val_acc: 0.6471\n",
      "Epoch 743/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5674 - acc: 0.8958 - val_loss: 1.4818 - val_acc: 0.5882\n",
      "Epoch 744/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5709 - acc: 0.8750 - val_loss: 1.4918 - val_acc: 0.5882\n",
      "Epoch 745/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5708 - acc: 0.8750 - val_loss: 1.4891 - val_acc: 0.6471\n",
      "Epoch 746/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5830 - acc: 0.8958 - val_loss: 1.5149 - val_acc: 0.5294\n",
      "Epoch 747/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5696 - acc: 0.8958 - val_loss: 1.4824 - val_acc: 0.5882\n",
      "Epoch 748/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5653 - acc: 0.8750 - val_loss: 1.4722 - val_acc: 0.6471\n",
      "Epoch 749/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5706 - acc: 0.8750 - val_loss: 1.4872 - val_acc: 0.6471\n",
      "Epoch 750/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5668 - acc: 0.8958 - val_loss: 1.5228 - val_acc: 0.5294\n",
      "Epoch 751/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5717 - acc: 0.9167 - val_loss: 1.4941 - val_acc: 0.5882\n",
      "Epoch 752/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5660 - acc: 0.8958 - val_loss: 1.4507 - val_acc: 0.6471\n",
      "Epoch 753/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5713 - acc: 0.8750 - val_loss: 1.4645 - val_acc: 0.5882\n",
      "Epoch 754/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5626 - acc: 0.8750 - val_loss: 1.4990 - val_acc: 0.5294\n",
      "Epoch 755/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5693 - acc: 0.9167 - val_loss: 1.5126 - val_acc: 0.5882\n",
      "Epoch 756/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5642 - acc: 0.9167 - val_loss: 1.4886 - val_acc: 0.5882\n",
      "Epoch 757/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5812 - acc: 0.8750 - val_loss: 1.4748 - val_acc: 0.5882\n",
      "Epoch 758/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5656 - acc: 0.8750 - val_loss: 1.5138 - val_acc: 0.5294\n",
      "Epoch 759/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5641 - acc: 0.9167 - val_loss: 1.5227 - val_acc: 0.5882\n",
      "Epoch 760/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5639 - acc: 0.9375 - val_loss: 1.4913 - val_acc: 0.5882\n",
      "Epoch 761/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5717 - acc: 0.8958 - val_loss: 1.4646 - val_acc: 0.6471\n",
      "Epoch 762/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5702 - acc: 0.8750 - val_loss: 1.4887 - val_acc: 0.5882\n",
      "Epoch 763/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5620 - acc: 0.9167 - val_loss: 1.5135 - val_acc: 0.5294\n",
      "Epoch 764/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5640 - acc: 0.9167 - val_loss: 1.4875 - val_acc: 0.5882\n",
      "Epoch 765/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5640 - acc: 0.9167 - val_loss: 1.4537 - val_acc: 0.6471\n",
      "Epoch 766/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5710 - acc: 0.8750 - val_loss: 1.4536 - val_acc: 0.5882\n",
      "Epoch 767/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5683 - acc: 0.8958 - val_loss: 1.5209 - val_acc: 0.5294\n",
      "Epoch 768/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5672 - acc: 0.8958 - val_loss: 1.5336 - val_acc: 0.5882\n",
      "Epoch 769/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5756 - acc: 0.9167 - val_loss: 1.4907 - val_acc: 0.6471\n",
      "Epoch 770/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5718 - acc: 0.8750 - val_loss: 1.4783 - val_acc: 0.6471\n",
      "Epoch 771/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5534 - acc: 0.8958 - val_loss: 1.5052 - val_acc: 0.5294\n",
      "Epoch 772/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5632 - acc: 0.8750 - val_loss: 1.5020 - val_acc: 0.5294\n",
      "Epoch 773/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5613 - acc: 0.8958 - val_loss: 1.4867 - val_acc: 0.6471\n",
      "Epoch 774/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5931 - acc: 0.8958 - val_loss: 1.4958 - val_acc: 0.5882\n",
      "Epoch 775/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5751 - acc: 0.8750 - val_loss: 1.4691 - val_acc: 0.5882\n",
      "Epoch 776/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5654 - acc: 0.8958 - val_loss: 1.4833 - val_acc: 0.5882\n",
      "Epoch 777/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5630 - acc: 0.8750 - val_loss: 1.5103 - val_acc: 0.5294\n",
      "Epoch 778/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5578 - acc: 0.9167 - val_loss: 1.5030 - val_acc: 0.5882\n",
      "Epoch 779/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5643 - acc: 0.8958 - val_loss: 1.4854 - val_acc: 0.6471\n",
      "Epoch 780/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5599 - acc: 0.8750 - val_loss: 1.5040 - val_acc: 0.5882\n",
      "Epoch 781/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5637 - acc: 0.8750 - val_loss: 1.4918 - val_acc: 0.5882\n",
      "Epoch 782/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5504 - acc: 0.8750 - val_loss: 1.5048 - val_acc: 0.5882\n",
      "Epoch 783/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5557 - acc: 0.9167 - val_loss: 1.5074 - val_acc: 0.5294\n",
      "Epoch 784/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.5556 - acc: 0.9167 - val_loss: 1.4817 - val_acc: 0.5882\n",
      "Epoch 785/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5566 - acc: 0.9167 - val_loss: 1.4580 - val_acc: 0.5882\n",
      "Epoch 786/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5566 - acc: 0.8750 - val_loss: 1.4801 - val_acc: 0.5882\n",
      "Epoch 787/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5548 - acc: 0.9167 - val_loss: 1.5189 - val_acc: 0.5294\n",
      "Epoch 788/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5554 - acc: 0.9375 - val_loss: 1.5161 - val_acc: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5653 - acc: 0.9167 - val_loss: 1.4902 - val_acc: 0.6471\n",
      "Epoch 790/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5553 - acc: 0.9167 - val_loss: 1.5099 - val_acc: 0.5882\n",
      "Epoch 791/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5751 - acc: 0.8750 - val_loss: 1.5266 - val_acc: 0.5882\n",
      "Epoch 792/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5962 - acc: 0.8958 - val_loss: 1.5138 - val_acc: 0.5882\n",
      "Epoch 793/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5631 - acc: 0.9375 - val_loss: 1.4801 - val_acc: 0.6471\n",
      "Epoch 794/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5496 - acc: 0.9167 - val_loss: 1.4841 - val_acc: 0.5882\n",
      "Epoch 795/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5630 - acc: 0.8750 - val_loss: 1.5068 - val_acc: 0.5882\n",
      "Epoch 796/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5544 - acc: 0.8958 - val_loss: 1.5138 - val_acc: 0.5882\n",
      "Epoch 797/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5620 - acc: 0.9167 - val_loss: 1.5079 - val_acc: 0.6471\n",
      "Epoch 798/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5645 - acc: 0.9375 - val_loss: 1.5191 - val_acc: 0.5882\n",
      "Epoch 799/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5542 - acc: 0.8958 - val_loss: 1.4938 - val_acc: 0.5882\n",
      "Epoch 800/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5579 - acc: 0.8958 - val_loss: 1.4816 - val_acc: 0.5882\n",
      "Epoch 801/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5527 - acc: 0.8958 - val_loss: 1.4975 - val_acc: 0.6471\n",
      "Epoch 802/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5652 - acc: 0.8750 - val_loss: 1.5185 - val_acc: 0.5882\n",
      "Epoch 803/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5538 - acc: 0.9375 - val_loss: 1.5587 - val_acc: 0.5294\n",
      "Epoch 804/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5607 - acc: 0.9167 - val_loss: 1.5032 - val_acc: 0.5882\n",
      "Epoch 805/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5591 - acc: 0.8750 - val_loss: 1.4798 - val_acc: 0.6471\n",
      "Epoch 806/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5513 - acc: 0.8750 - val_loss: 1.5106 - val_acc: 0.6471\n",
      "Epoch 807/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5608 - acc: 0.9375 - val_loss: 1.5469 - val_acc: 0.5882\n",
      "Epoch 808/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5695 - acc: 0.9167 - val_loss: 1.4937 - val_acc: 0.5882\n",
      "Epoch 809/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5495 - acc: 0.8958 - val_loss: 1.4790 - val_acc: 0.5882\n",
      "Epoch 810/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.5468 - acc: 0.8958 - val_loss: 1.4946 - val_acc: 0.5294\n",
      "Epoch 811/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5460 - acc: 0.9167 - val_loss: 1.5152 - val_acc: 0.5882\n",
      "Epoch 812/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5499 - acc: 0.9167 - val_loss: 1.4975 - val_acc: 0.6471\n",
      "Epoch 813/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5431 - acc: 0.8958 - val_loss: 1.4711 - val_acc: 0.5882\n",
      "Epoch 814/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5461 - acc: 0.8750 - val_loss: 1.4805 - val_acc: 0.5882\n",
      "Epoch 815/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5416 - acc: 0.9167 - val_loss: 1.5102 - val_acc: 0.5882\n",
      "Epoch 816/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5488 - acc: 0.9375 - val_loss: 1.5067 - val_acc: 0.5882\n",
      "Epoch 817/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5604 - acc: 0.8958 - val_loss: 1.4947 - val_acc: 0.6471\n",
      "Epoch 818/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5421 - acc: 0.8958 - val_loss: 1.5177 - val_acc: 0.5294\n",
      "Epoch 819/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5482 - acc: 0.9167 - val_loss: 1.5346 - val_acc: 0.5294\n",
      "Epoch 820/1000\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5598 - acc: 1.000 - 0s 63us/step - loss: 0.5452 - acc: 0.9375 - val_loss: 1.5006 - val_acc: 0.6471\n",
      "Epoch 821/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5419 - acc: 0.8958 - val_loss: 1.5030 - val_acc: 0.6471\n",
      "Epoch 822/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5430 - acc: 0.8958 - val_loss: 1.5126 - val_acc: 0.5882\n",
      "Epoch 823/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5410 - acc: 0.9167 - val_loss: 1.5071 - val_acc: 0.5882\n",
      "Epoch 824/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5401 - acc: 0.9167 - val_loss: 1.5085 - val_acc: 0.5882\n",
      "Epoch 825/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5553 - acc: 0.9167 - val_loss: 1.5195 - val_acc: 0.5294\n",
      "Epoch 826/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5373 - acc: 0.9375 - val_loss: 1.4935 - val_acc: 0.6471\n",
      "Epoch 827/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5389 - acc: 0.9167 - val_loss: 1.4824 - val_acc: 0.6471\n",
      "Epoch 828/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5434 - acc: 0.8958 - val_loss: 1.4965 - val_acc: 0.5882\n",
      "Epoch 829/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5399 - acc: 0.9167 - val_loss: 1.5047 - val_acc: 0.6471\n",
      "Epoch 830/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5440 - acc: 0.9167 - val_loss: 1.4996 - val_acc: 0.6471\n",
      "Epoch 831/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5400 - acc: 0.9167 - val_loss: 1.5113 - val_acc: 0.5882\n",
      "Epoch 832/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5420 - acc: 0.9167 - val_loss: 1.5061 - val_acc: 0.5882\n",
      "Epoch 833/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5396 - acc: 0.9167 - val_loss: 1.4975 - val_acc: 0.6471\n",
      "Epoch 834/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5444 - acc: 0.9167 - val_loss: 1.5010 - val_acc: 0.6471\n",
      "Epoch 835/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5406 - acc: 0.9167 - val_loss: 1.4920 - val_acc: 0.5882\n",
      "Epoch 836/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5392 - acc: 0.9167 - val_loss: 1.5167 - val_acc: 0.5294\n",
      "Epoch 837/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5422 - acc: 0.9167 - val_loss: 1.5445 - val_acc: 0.5294\n",
      "Epoch 838/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5371 - acc: 0.9583 - val_loss: 1.5083 - val_acc: 0.6471\n",
      "Epoch 839/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5377 - acc: 0.9167 - val_loss: 1.4980 - val_acc: 0.6471\n",
      "Epoch 840/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5449 - acc: 0.9167 - val_loss: 1.5154 - val_acc: 0.5882\n",
      "Epoch 841/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5417 - acc: 0.8750 - val_loss: 1.5190 - val_acc: 0.5882\n",
      "Epoch 842/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5344 - acc: 0.9167 - val_loss: 1.5082 - val_acc: 0.6471\n",
      "Epoch 843/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5442 - acc: 0.9167 - val_loss: 1.5140 - val_acc: 0.6471\n",
      "Epoch 844/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5324 - acc: 0.9167 - val_loss: 1.5425 - val_acc: 0.5294\n",
      "Epoch 845/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5367 - acc: 0.9167 - val_loss: 1.5299 - val_acc: 0.5882\n",
      "Epoch 846/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5359 - acc: 0.9167 - val_loss: 1.5072 - val_acc: 0.5882\n",
      "Epoch 847/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5341 - acc: 0.9167 - val_loss: 1.4991 - val_acc: 0.6471\n",
      "Epoch 848/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5371 - acc: 0.9167 - val_loss: 1.5148 - val_acc: 0.5882\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 63us/step - loss: 0.5322 - acc: 0.9167 - val_loss: 1.5135 - val_acc: 0.5882\n",
      "Epoch 850/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5334 - acc: 0.9375 - val_loss: 1.5075 - val_acc: 0.5882\n",
      "Epoch 851/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5319 - acc: 0.9375 - val_loss: 1.5345 - val_acc: 0.5294\n",
      "Epoch 852/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5384 - acc: 0.8958 - val_loss: 1.5380 - val_acc: 0.5882\n",
      "Epoch 853/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5314 - acc: 0.9167 - val_loss: 1.5484 - val_acc: 0.5882\n",
      "Epoch 854/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5498 - acc: 0.8958 - val_loss: 1.5223 - val_acc: 0.5882\n",
      "Epoch 855/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5393 - acc: 0.9167 - val_loss: 1.5064 - val_acc: 0.6471\n",
      "Epoch 856/1000\n",
      "48/48 [==============================] - 0s 84us/step - loss: 0.5299 - acc: 0.9167 - val_loss: 1.5073 - val_acc: 0.6471\n",
      "Epoch 857/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5285 - acc: 0.9167 - val_loss: 1.5081 - val_acc: 0.5882\n",
      "Epoch 858/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5314 - acc: 0.8958 - val_loss: 1.5138 - val_acc: 0.6471\n",
      "Epoch 859/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5303 - acc: 0.8958 - val_loss: 1.5310 - val_acc: 0.5882\n",
      "Epoch 860/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5292 - acc: 0.9375 - val_loss: 1.5307 - val_acc: 0.5882\n",
      "Epoch 861/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5273 - acc: 0.9375 - val_loss: 1.5095 - val_acc: 0.5882\n",
      "Epoch 862/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5306 - acc: 0.9167 - val_loss: 1.4997 - val_acc: 0.5882\n",
      "Epoch 863/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5318 - acc: 0.9167 - val_loss: 1.5029 - val_acc: 0.5882\n",
      "Epoch 864/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5376 - acc: 0.9167 - val_loss: 1.5395 - val_acc: 0.5882\n",
      "Epoch 865/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5284 - acc: 0.9167 - val_loss: 1.5160 - val_acc: 0.6471\n",
      "Epoch 866/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5259 - acc: 0.9167 - val_loss: 1.5101 - val_acc: 0.5882\n",
      "Epoch 867/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5303 - acc: 0.9167 - val_loss: 1.5160 - val_acc: 0.6471\n",
      "Epoch 868/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5270 - acc: 0.9167 - val_loss: 1.5325 - val_acc: 0.5882\n",
      "Epoch 869/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5279 - acc: 0.9583 - val_loss: 1.5293 - val_acc: 0.5882\n",
      "Epoch 870/1000\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5625 - acc: 0.960 - 0s 63us/step - loss: 0.5339 - acc: 0.9583 - val_loss: 1.4958 - val_acc: 0.5882\n",
      "Epoch 871/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5248 - acc: 0.9167 - val_loss: 1.5008 - val_acc: 0.5882\n",
      "Epoch 872/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5550 - acc: 0.8750 - val_loss: 1.5242 - val_acc: 0.5882\n",
      "Epoch 873/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5300 - acc: 0.9375 - val_loss: 1.6047 - val_acc: 0.5882\n",
      "Epoch 874/1000\n",
      "48/48 [==============================] - 0s 82us/step - loss: 0.5436 - acc: 0.9792 - val_loss: 1.5727 - val_acc: 0.5882\n",
      "Epoch 875/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5319 - acc: 0.9375 - val_loss: 1.5195 - val_acc: 0.6471\n",
      "Epoch 876/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5299 - acc: 0.8958 - val_loss: 1.5277 - val_acc: 0.5882\n",
      "Epoch 877/1000\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5562 - acc: 0.840 - 0s 83us/step - loss: 0.5391 - acc: 0.8750 - val_loss: 1.5480 - val_acc: 0.5882\n",
      "Epoch 878/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5489 - acc: 0.9167 - val_loss: 1.5468 - val_acc: 0.5882\n",
      "Epoch 879/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5322 - acc: 0.9583 - val_loss: 1.5116 - val_acc: 0.6471\n",
      "Epoch 880/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5556 - acc: 0.8958 - val_loss: 1.5151 - val_acc: 0.5882\n",
      "Epoch 881/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5330 - acc: 0.8958 - val_loss: 1.5664 - val_acc: 0.5294\n",
      "Epoch 882/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5269 - acc: 0.9792 - val_loss: 1.5766 - val_acc: 0.5882\n",
      "Epoch 883/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5373 - acc: 0.9583 - val_loss: 1.5372 - val_acc: 0.5882\n",
      "Epoch 884/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5294 - acc: 0.9583 - val_loss: 1.4995 - val_acc: 0.6471\n",
      "Epoch 885/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5437 - acc: 0.8750 - val_loss: 1.5304 - val_acc: 0.5882\n",
      "Epoch 886/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5339 - acc: 0.9167 - val_loss: 1.5484 - val_acc: 0.5294\n",
      "Epoch 887/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5230 - acc: 0.9583 - val_loss: 1.5511 - val_acc: 0.5882\n",
      "Epoch 888/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5305 - acc: 0.9583 - val_loss: 1.5193 - val_acc: 0.6471\n",
      "Epoch 889/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5269 - acc: 0.9167 - val_loss: 1.5198 - val_acc: 0.5882\n",
      "Epoch 890/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5278 - acc: 0.8958 - val_loss: 1.5158 - val_acc: 0.5882\n",
      "Epoch 891/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5241 - acc: 0.9167 - val_loss: 1.5254 - val_acc: 0.6471\n",
      "Epoch 892/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5193 - acc: 0.9375 - val_loss: 1.5280 - val_acc: 0.6471\n",
      "Epoch 893/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5191 - acc: 0.9167 - val_loss: 1.5253 - val_acc: 0.6471\n",
      "Epoch 894/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5352 - acc: 0.9167 - val_loss: 1.5407 - val_acc: 0.5882\n",
      "Epoch 895/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5220 - acc: 0.9167 - val_loss: 1.5180 - val_acc: 0.6471\n",
      "Epoch 896/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5274 - acc: 0.9167 - val_loss: 1.5258 - val_acc: 0.6471\n",
      "Epoch 897/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5172 - acc: 0.9583 - val_loss: 1.5325 - val_acc: 0.5882\n",
      "Epoch 898/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5196 - acc: 0.9167 - val_loss: 1.5218 - val_acc: 0.5882\n",
      "Epoch 899/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5203 - acc: 0.9167 - val_loss: 1.5456 - val_acc: 0.5882\n",
      "Epoch 900/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5280 - acc: 0.8958 - val_loss: 1.5337 - val_acc: 0.6471\n",
      "Epoch 901/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5228 - acc: 0.9167 - val_loss: 1.5638 - val_acc: 0.5882\n",
      "Epoch 902/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5388 - acc: 0.9792 - val_loss: 1.5764 - val_acc: 0.5294\n",
      "Epoch 903/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5378 - acc: 0.9167 - val_loss: 1.5173 - val_acc: 0.5882\n",
      "Epoch 904/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5399 - acc: 0.8750 - val_loss: 1.5140 - val_acc: 0.6471\n",
      "Epoch 905/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5312 - acc: 0.9167 - val_loss: 1.5627 - val_acc: 0.5882\n",
      "Epoch 906/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5333 - acc: 0.9583 - val_loss: 1.5877 - val_acc: 0.5294\n",
      "Epoch 907/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5328 - acc: 0.9375 - val_loss: 1.5225 - val_acc: 0.5882\n",
      "Epoch 908/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5310 - acc: 0.8958 - val_loss: 1.5037 - val_acc: 0.6471\n",
      "Epoch 909/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 42us/step - loss: 0.5333 - acc: 0.9167 - val_loss: 1.5207 - val_acc: 0.6471\n",
      "Epoch 910/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5293 - acc: 0.9583 - val_loss: 1.5523 - val_acc: 0.5882\n",
      "Epoch 911/1000\n",
      "48/48 [==============================] - 0s 42us/step - loss: 0.5294 - acc: 0.9583 - val_loss: 1.5264 - val_acc: 0.5882\n",
      "Epoch 912/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5582 - acc: 0.8542 - val_loss: 1.5172 - val_acc: 0.6471\n",
      "Epoch 913/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5244 - acc: 0.9167 - val_loss: 1.5722 - val_acc: 0.5882\n",
      "Epoch 914/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5410 - acc: 0.9583 - val_loss: 1.6049 - val_acc: 0.5882\n",
      "Epoch 915/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5357 - acc: 0.9583 - val_loss: 1.5331 - val_acc: 0.5882\n",
      "Epoch 916/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5230 - acc: 0.8958 - val_loss: 1.5165 - val_acc: 0.6471\n",
      "Epoch 917/1000\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.5707 - acc: 0.880 - 0s 63us/step - loss: 0.5412 - acc: 0.8958 - val_loss: 1.5261 - val_acc: 0.6471\n",
      "Epoch 918/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5092 - acc: 0.9583 - val_loss: 1.5891 - val_acc: 0.5294\n",
      "Epoch 919/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5457 - acc: 0.9375 - val_loss: 1.5853 - val_acc: 0.5294\n",
      "Epoch 920/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5236 - acc: 0.9583 - val_loss: 1.5223 - val_acc: 0.6471\n",
      "Epoch 921/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5311 - acc: 0.9167 - val_loss: 1.5234 - val_acc: 0.6471\n",
      "Epoch 922/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5246 - acc: 0.9167 - val_loss: 1.5501 - val_acc: 0.5882\n",
      "Epoch 923/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5203 - acc: 0.9167 - val_loss: 1.5586 - val_acc: 0.5882\n",
      "Epoch 924/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5347 - acc: 0.9167 - val_loss: 1.5300 - val_acc: 0.6471\n",
      "Epoch 925/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5157 - acc: 0.9167 - val_loss: 1.5550 - val_acc: 0.6471\n",
      "Epoch 926/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5119 - acc: 0.9792 - val_loss: 1.5551 - val_acc: 0.6471\n",
      "Epoch 927/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5122 - acc: 0.9583 - val_loss: 1.5495 - val_acc: 0.5882\n",
      "Epoch 928/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5102 - acc: 0.9375 - val_loss: 1.5384 - val_acc: 0.6471\n",
      "Epoch 929/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5106 - acc: 0.9167 - val_loss: 1.5476 - val_acc: 0.6471\n",
      "Epoch 930/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5081 - acc: 0.9583 - val_loss: 1.5499 - val_acc: 0.6471\n",
      "Epoch 931/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5117 - acc: 0.9792 - val_loss: 1.5220 - val_acc: 0.6471\n",
      "Epoch 932/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5118 - acc: 0.9375 - val_loss: 1.5176 - val_acc: 0.6471\n",
      "Epoch 933/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5154 - acc: 0.9167 - val_loss: 1.5282 - val_acc: 0.6471\n",
      "Epoch 934/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5098 - acc: 0.9167 - val_loss: 1.5482 - val_acc: 0.6471\n",
      "Epoch 935/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5113 - acc: 0.9375 - val_loss: 1.5702 - val_acc: 0.5882\n",
      "Epoch 936/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5191 - acc: 0.9792 - val_loss: 1.5539 - val_acc: 0.5882\n",
      "Epoch 937/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5246 - acc: 0.9167 - val_loss: 1.5215 - val_acc: 0.6471\n",
      "Epoch 938/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5135 - acc: 0.9167 - val_loss: 1.5284 - val_acc: 0.5882\n",
      "Epoch 939/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5205 - acc: 0.9375 - val_loss: 1.5731 - val_acc: 0.5294\n",
      "Epoch 940/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5126 - acc: 0.9792 - val_loss: 1.5450 - val_acc: 0.6471\n",
      "Epoch 941/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5329 - acc: 0.9167 - val_loss: 1.5297 - val_acc: 0.6471\n",
      "Epoch 942/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5138 - acc: 0.9167 - val_loss: 1.5367 - val_acc: 0.5882\n",
      "Epoch 943/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5292 - acc: 0.9375 - val_loss: 1.5941 - val_acc: 0.5882\n",
      "Epoch 944/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5292 - acc: 0.9792 - val_loss: 1.5222 - val_acc: 0.5882\n",
      "Epoch 945/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5034 - acc: 0.9167 - val_loss: 1.5145 - val_acc: 0.6471\n",
      "Epoch 946/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5326 - acc: 0.8958 - val_loss: 1.5330 - val_acc: 0.6471\n",
      "Epoch 947/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5122 - acc: 0.9375 - val_loss: 1.6021 - val_acc: 0.5882\n",
      "Epoch 948/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5159 - acc: 0.9792 - val_loss: 1.5785 - val_acc: 0.6471\n",
      "Epoch 949/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5104 - acc: 0.9375 - val_loss: 1.5276 - val_acc: 0.6471\n",
      "Epoch 950/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5285 - acc: 0.9167 - val_loss: 1.5166 - val_acc: 0.6471\n",
      "Epoch 951/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5109 - acc: 0.9583 - val_loss: 1.5744 - val_acc: 0.5882\n",
      "Epoch 952/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5187 - acc: 0.9792 - val_loss: 1.5806 - val_acc: 0.5882\n",
      "Epoch 953/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5122 - acc: 0.9375 - val_loss: 1.5604 - val_acc: 0.6471\n",
      "Epoch 954/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5172 - acc: 0.9375 - val_loss: 1.5696 - val_acc: 0.6471\n",
      "Epoch 955/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5085 - acc: 0.9167 - val_loss: 1.5797 - val_acc: 0.5882\n",
      "Epoch 956/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5136 - acc: 0.9375 - val_loss: 1.5847 - val_acc: 0.5882\n",
      "Epoch 957/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5119 - acc: 0.9167 - val_loss: 1.5538 - val_acc: 0.6471\n",
      "Epoch 958/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5096 - acc: 0.9167 - val_loss: 1.5664 - val_acc: 0.6471\n",
      "Epoch 959/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5080 - acc: 0.9375 - val_loss: 1.5631 - val_acc: 0.5882\n",
      "Epoch 960/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5082 - acc: 0.9375 - val_loss: 1.5671 - val_acc: 0.5882\n",
      "Epoch 961/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5061 - acc: 0.9375 - val_loss: 1.5444 - val_acc: 0.6471\n",
      "Epoch 962/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5217 - acc: 0.9167 - val_loss: 1.5467 - val_acc: 0.6471\n",
      "Epoch 963/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5026 - acc: 0.9583 - val_loss: 1.5223 - val_acc: 0.6471\n",
      "Epoch 964/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5105 - acc: 0.9375 - val_loss: 1.5404 - val_acc: 0.5882\n",
      "Epoch 965/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5328 - acc: 0.8542 - val_loss: 1.5289 - val_acc: 0.6471\n",
      "Epoch 966/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5035 - acc: 0.9583 - val_loss: 1.5802 - val_acc: 0.5882\n",
      "Epoch 967/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5173 - acc: 0.9583 - val_loss: 1.5536 - val_acc: 0.6471\n",
      "Epoch 968/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5141 - acc: 0.9375 - val_loss: 1.5396 - val_acc: 0.5882\n",
      "Epoch 969/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 63us/step - loss: 0.5141 - acc: 0.9167 - val_loss: 1.5465 - val_acc: 0.5882\n",
      "Epoch 970/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5249 - acc: 0.9375 - val_loss: 1.5677 - val_acc: 0.6471\n",
      "Epoch 971/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5146 - acc: 0.9792 - val_loss: 1.5557 - val_acc: 0.6471\n",
      "Epoch 972/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5022 - acc: 0.9583 - val_loss: 1.5416 - val_acc: 0.5882\n",
      "Epoch 973/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5137 - acc: 0.9167 - val_loss: 1.5648 - val_acc: 0.5882\n",
      "Epoch 974/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5130 - acc: 0.9375 - val_loss: 1.5596 - val_acc: 0.6471\n",
      "Epoch 975/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5038 - acc: 0.9375 - val_loss: 1.5486 - val_acc: 0.6471\n",
      "Epoch 976/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.4996 - acc: 0.9167 - val_loss: 1.5487 - val_acc: 0.6471\n",
      "Epoch 977/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5021 - acc: 0.9375 - val_loss: 1.5770 - val_acc: 0.5882\n",
      "Epoch 978/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5061 - acc: 0.9375 - val_loss: 1.5459 - val_acc: 0.6471\n",
      "Epoch 979/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4982 - acc: 0.9583 - val_loss: 1.5531 - val_acc: 0.6471\n",
      "Epoch 980/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.4966 - acc: 0.9375 - val_loss: 1.5597 - val_acc: 0.6471\n",
      "Epoch 981/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4982 - acc: 0.9167 - val_loss: 1.5662 - val_acc: 0.5882\n",
      "Epoch 982/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5061 - acc: 0.9583 - val_loss: 1.5632 - val_acc: 0.5882\n",
      "Epoch 983/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4993 - acc: 0.9167 - val_loss: 1.5581 - val_acc: 0.6471\n",
      "Epoch 984/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.5002 - acc: 0.9583 - val_loss: 1.5697 - val_acc: 0.6471\n",
      "Epoch 985/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5036 - acc: 0.9792 - val_loss: 1.5507 - val_acc: 0.6471\n",
      "Epoch 986/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5006 - acc: 0.9167 - val_loss: 1.5400 - val_acc: 0.6471\n",
      "Epoch 987/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4955 - acc: 0.9375 - val_loss: 1.5531 - val_acc: 0.6471\n",
      "Epoch 988/1000\n",
      "48/48 [==============================] - 0s 104us/step - loss: 0.5025 - acc: 0.9792 - val_loss: 1.5846 - val_acc: 0.6471\n",
      "Epoch 989/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5049 - acc: 0.9375 - val_loss: 1.5461 - val_acc: 0.6471\n",
      "Epoch 990/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.4960 - acc: 0.9375 - val_loss: 1.5455 - val_acc: 0.6471\n",
      "Epoch 991/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5106 - acc: 0.9167 - val_loss: 1.5491 - val_acc: 0.6471\n",
      "Epoch 992/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5005 - acc: 0.9792 - val_loss: 1.5637 - val_acc: 0.5882\n",
      "Epoch 993/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4972 - acc: 0.9583 - val_loss: 1.5472 - val_acc: 0.6471\n",
      "Epoch 994/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5014 - acc: 0.9375 - val_loss: 1.5547 - val_acc: 0.6471\n",
      "Epoch 995/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4990 - acc: 0.9375 - val_loss: 1.5575 - val_acc: 0.6471\n",
      "Epoch 996/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4924 - acc: 0.9583 - val_loss: 1.5695 - val_acc: 0.5882\n",
      "Epoch 997/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.5022 - acc: 0.9583 - val_loss: 1.5628 - val_acc: 0.5882\n",
      "Epoch 998/1000\n",
      "48/48 [==============================] - 0s 83us/step - loss: 0.4998 - acc: 0.9167 - val_loss: 1.5557 - val_acc: 0.6471\n",
      "Epoch 999/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.5044 - acc: 0.9375 - val_loss: 1.5581 - val_acc: 0.6471\n",
      "Epoch 1000/1000\n",
      "48/48 [==============================] - 0s 63us/step - loss: 0.4967 - acc: 0.9583 - val_loss: 1.5447 - val_acc: 0.6471\n"
     ]
    }
   ],
   "source": [
    "#X_train is 0.8 of total data set so cross validation needs to be 0.25 of X_train to be 0.2 of total dataset\n",
    "history = model.fit(X_train, y_train_oneHot, validation_split=0.25, epochs=1000, batch_size=25, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae5e046240>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "17/17 [==============================] - 0s 59us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.894911766052246, 0.529411792755127]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=y_test_oneHot,batch_size=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
