{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\auria\\Anaconda3\\envs\\keras_environment\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\auria\\Anaconda3\\envs\\keras_environment\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.functions import import_data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import talos as ta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X train also contains cross validation set. model.fit will split it between training and cross validation\n",
    "X, X_train, X_test, y_train, y_test = import_data('Database_2.csv')\n",
    "input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_picker_model(x_train, y_train, x_val, y_val, params):\n",
    "    #Build model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_layer'], activation='relu', input_dim=input_size,kernel_regularizer=regularizers.l2(0.00), activity_regularizer=regularizers.l1(0.00)))\n",
    "    model.add(Dense(params['second_layer'], activation='relu',kernel_regularizer=regularizers.l2(0.00), activity_regularizer=regularizers.l1(0.00)))\n",
    "    model.add(Dense(params['third_layer'], activation='relu',kernel_regularizer=regularizers.l2(0.00), activity_regularizer=regularizers.l1(0.00)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #compile model\n",
    "    optimizer = optimizers.Adam(lr=0.001, beta_1 = 0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #fit\n",
    "    out = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build parameters testing dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'first_layer' : [8, 16, 32, 64, 128, 256, 512],\n",
    "     'second_layer' : [8, 16, 32, 64, 128, 256, 512],\n",
    "     'third_layer' : [8, 16, 32, 64, 128, 256, 512],\n",
    "    'batch_size' : [64, 128, 256, 512],\n",
    "    'epochs' : [10, 20, 40, 80, 160, 320]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/8232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\auria\\Anaconda3\\envs\\keras_environment\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\auria\\Anaconda3\\envs\\keras_environment\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8232/8232 [17:41:32<00:00, 15.48s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=X_train,\n",
    "            y=y_train,\n",
    "            model=stock_picker_model,\n",
    "            params=p,\n",
    "            dataset_name='3_layers_tuning_report',\n",
    "            experiment_no='1')\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
